{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of CS230_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XRwn7WkCE89Q",
        "-ZzvKzJu8zkP",
        "f_pPK0lq9fNE",
        "W9my4tlYcwUN",
        "psmsOlv-FIjx"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTTJ-J9R-0Ap"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lf7m3fY7RJJ",
        "outputId": "2bb4ac69-6831-4aee-d87c-d4c09bd4856e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QW3BH1m-iZ6",
        "outputId": "e0385bc3-d508-4d05-dc0c-f3ea43ac9ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Flatten,BatchNormalization\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, merge, ZeroPadding2D\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "import keras.metrics as metrics\n",
        "tf.__version__"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szgqEprIJyrN",
        "outputId": "8c0ecd09-0c97-449a-f4fa-beba6d06aa8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "!wget --no-check-certificate https://apps.peer.berkeley.edu/phichallenge/dataset/task5_collapse_mode.zip\n",
        "!unzip task5_collapse_mode.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-26 23:06:07--  https://apps.peer.berkeley.edu/phichallenge/dataset/task5_collapse_mode.zip\n",
            "Resolving apps.peer.berkeley.edu (apps.peer.berkeley.edu)... 128.32.143.24, 2607:f140:0:f::24\n",
            "Connecting to apps.peer.berkeley.edu (apps.peer.berkeley.edu)|128.32.143.24|:443... connected.\n",
            "WARNING: cannot verify apps.peer.berkeley.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232967101 (222M) [application/zip]\n",
            "Saving to: ‘task5_collapse_mode.zip’\n",
            "\n",
            "task5_collapse_mode 100%[===================>] 222.17M  39.5MB/s    in 6.0s    \n",
            "\n",
            "2020-10-26 23:06:14 (36.7 MB/s) - ‘task5_collapse_mode.zip’ saved [232967101/232967101]\n",
            "\n",
            "Archive:  task5_collapse_mode.zip\n",
            "   creating: task5/\n",
            "  inflating: task5/task5_X_test.npy  \n",
            "  inflating: task5/task5_y_test.npy  \n",
            "  inflating: task5/task5_X_train.npy  \n",
            "  inflating: task5/task5_y_train.npy  \n",
            "  inflating: task5/license.txt       \n",
            "  inflating: task5/README.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqnXgqFyyA_i",
        "outputId": "29ade4e6-ad73-414d-bda2-4df377dd049c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate https://apps.peer.berkeley.edu/phichallenge/dataset/task1_scene_level.zip\n",
        "!unzip task1_scene_level.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-30 00:43:29--  https://apps.peer.berkeley.edu/phichallenge/dataset/task1_scene_level.zip\n",
            "Resolving apps.peer.berkeley.edu (apps.peer.berkeley.edu)... 128.32.143.24, 2607:f140:0:f::24\n",
            "Connecting to apps.peer.berkeley.edu (apps.peer.berkeley.edu)|128.32.143.24|:443... connected.\n",
            "WARNING: cannot verify apps.peer.berkeley.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3551945848 (3.3G) [application/zip]\n",
            "Saving to: ‘task1_scene_level.zip.1’\n",
            "\n",
            "task1_scene_level.z 100%[===================>]   3.31G  19.2MB/s    in 3m 1s   \n",
            "\n",
            "2020-10-30 00:46:31 (18.7 MB/s) - ‘task1_scene_level.zip.1’ saved [3551945848/3551945848]\n",
            "\n",
            "Archive:  task1_scene_level.zip\n",
            "replace task1/license.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-9p3bk-5V3"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ohAmuyOJjZx"
      },
      "source": [
        "base_file_path = 'task1/'\n",
        "train_x_path = base_file_path + 'task1_X_train.npy'\n",
        "test_x_path = base_file_path + 'task1_X_test.npy'\n",
        "train_y_path = base_file_path + 'task1_y_train.npy'\n",
        "test_y_path = base_file_path + 'task1_y_test.npy'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqx8bcoJ_JFa"
      },
      "source": [
        "raw_train_x = np.load(train_x_path)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(raw_train_x)\n",
        "\n",
        "raw_train_y= np.load(train_y_path)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(raw_train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt4b1gvKBEPy"
      },
      "source": [
        "split = 0.8\n",
        "\n",
        "n = raw_train_x.shape[0]\n",
        "train_x = raw_train_x[0:int(n*split)]\n",
        "val_x = raw_train_x[int(n*split):]\n",
        "train_y = raw_train_y[0:int(n*split)]\n",
        "val_y = raw_train_y[int(n*split):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bepiMKPxG6aK"
      },
      "source": [
        "input_shape = train_x.shape[1:]\n",
        "num_class = train_y.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBpzkxEnADl4",
        "outputId": "a42c6bfb-954e-42b1-ecff-ac71d94f4de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_x = np.load(test_x_path)\n",
        "test_y = np.load(test_y_path)\n",
        "test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2997, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VdN5iVqBwgW"
      },
      "source": [
        "index = 601 \n",
        "train_x_w[index] += 80\n",
        "print(train_x_w[index])\n",
        "plt.imshow(train_x_w[index].astype('uint8'))\n",
        "print (\"y = \" + str(train_y_w[index]))\n",
        "train_x_w[index] -= 80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBBM44nyJjbO"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVb1jzPJjbR"
      },
      "source": [
        "from keras.preprocessing.image import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXXzJC-dJjbe"
      },
      "source": [
        "# Not 100% sure how this works but I think a data generator is the way to go\n",
        "# Documentation: https://keras.io/api/preprocessing/image/ \n",
        "base_generator = ImageDataGenerator(\n",
        "    data_format = 'channels_last'\n",
        ")\n",
        "\n",
        "data_augmentation_generator = ImageDataGenerator(\n",
        "  data_format = 'channels_last',\n",
        "  horizontal_flip = True, \n",
        "  rotation_range = 30, \n",
        "  validation_split = None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8PMnKcvJjbo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho3dneuN_s5i"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3K0B9mLkKM"
      },
      "source": [
        "# Aggregation Statistics\n",
        "\n",
        "train_performance = {}\n",
        "val_performance = {}\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQCCo1MkIadG"
      },
      "source": [
        "def compile_and_fit(model, generator, patience=2, MAX_EPOCHS = 30, early_stop = False, val_split = 0.1, decay_step = 500,\n",
        "                    batch_size = 64, initial_lr = 1e-3, lr_decay_rate = 0.9):\n",
        "\n",
        "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate= initial_lr,\n",
        "        decay_steps= decay_step,\n",
        "        decay_rate= lr_decay_rate)at\n",
        "  \n",
        "    model.compile(loss=tf.losses.categorical_crossentropy,\n",
        "                optimizer=tf.optimizers.Adam(learning_rate= lr_schedule),\n",
        "                metrics=[metrics.Accuracy(), metrics.AUC()])\n",
        "    \n",
        "  \n",
        "    if (early_stop == False):\n",
        "    # history = model.fit(train_x, train_y, epochs=MAX_EPOCHS, batch_size = batch_size, )\n",
        "        history = model.fit(generator.flow(train_x, train_y, batch_size = batch_size), epochs = MAX_EPOCHS, validation_data = (val_x, val_y))\n",
        "    else:\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                        patience=patience,\n",
        "                                                        mode='min')\n",
        "        history = model.fit(train_x, train_y, epochs=MAX_EPOCHS, batch_size = batch_size, validation_split = val_split, callbacks=[early_stopping])\n",
        "\n",
        "    return history"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvG1KKSbLrtf"
      },
      "source": [
        "def evaluate_model(model, model_name, verbose = 1):\n",
        "  train_performance[model_name] = model.evaluate(train_x, train_y, verbose= 1)\n",
        "  val_performance[model_name] = model.evaluate(val_x, val_y, verbose= 1)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zef_2koUGMzc"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMrgVUWnGSz6",
        "outputId": "52557ed7-9b89-424c-8d8b-5331684a3b78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layers=[\n",
        "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",activation=tf.nn.relu,input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "        \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=128,activation=tf.nn.relu),\n",
        "    \n",
        "    tf.keras.layers.Dense(units=num_class, activation=tf.nn.softmax)\n",
        "]\n",
        "\n",
        "baseline=tf.keras.Sequential(layers)\n",
        "baseline.summary()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               25690240  \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 25,710,019\n",
            "Trainable params: 25,710,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUeLC8BKGMRT",
        "outputId": "60e022c6-c407-4752-e5e5-aa65e42ba60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        }
      },
      "source": [
        "history = compile_and_fit(baseline, base_generator, MAX_EPOCHS = 30)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "304/304 [==============================] - 18s 58ms/step - loss: 0.0941 - accuracy: 0.1017 - auc_3: 0.9963 - val_loss: 1.4184 - val_accuracy: 0.0584 - val_auc_3: 0.8911\n",
            "Epoch 2/20\n",
            "304/304 [==============================] - 15s 50ms/step - loss: 0.0711 - accuracy: 0.1097 - auc_3: 0.9976 - val_loss: 1.7800 - val_accuracy: 0.0876 - val_auc_3: 0.8803\n",
            "Epoch 3/20\n",
            "304/304 [==============================] - 15s 50ms/step - loss: 0.0964 - accuracy: 0.0971 - auc_3: 0.9962 - val_loss: 1.5944 - val_accuracy: 0.0583 - val_auc_3: 0.8854\n",
            "Epoch 4/20\n",
            "304/304 [==============================] - 15s 50ms/step - loss: 0.0562 - accuracy: 0.1203 - auc_3: 0.9984 - val_loss: 2.0498 - val_accuracy: 0.0609 - val_auc_3: 0.8635\n",
            "Epoch 5/20\n",
            "304/304 [==============================] - 15s 49ms/step - loss: 0.0542 - accuracy: 0.1436 - auc_3: 0.9986 - val_loss: 1.8652 - val_accuracy: 0.1104 - val_auc_3: 0.8816\n",
            "Epoch 6/20\n",
            "304/304 [==============================] - 15s 49ms/step - loss: 0.0415 - accuracy: 0.1581 - auc_3: 0.9990 - val_loss: 2.3006 - val_accuracy: 0.1216 - val_auc_3: 0.8755\n",
            "Epoch 7/20\n",
            "304/304 [==============================] - 15s 49ms/step - loss: 0.0345 - accuracy: 0.1885 - auc_3: 0.9994 - val_loss: 1.9157 - val_accuracy: 0.1071 - val_auc_3: 0.8812\n",
            "Epoch 8/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0341 - accuracy: 0.2059 - auc_3: 0.9991 - val_loss: 2.1752 - val_accuracy: 0.1149 - val_auc_3: 0.8720\n",
            "Epoch 9/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0323 - accuracy: 0.2311 - auc_3: 0.9992 - val_loss: 2.2479 - val_accuracy: 0.1394 - val_auc_3: 0.8799\n",
            "Epoch 10/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0215 - accuracy: 0.2181 - auc_3: 0.9997 - val_loss: 2.4846 - val_accuracy: 0.1781 - val_auc_3: 0.8797\n",
            "Epoch 11/20\n",
            "304/304 [==============================] - 15s 49ms/step - loss: 0.0225 - accuracy: 0.2486 - auc_3: 0.9996 - val_loss: 2.3587 - val_accuracy: 0.1438 - val_auc_3: 0.8756\n",
            "Epoch 12/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0248 - accuracy: 0.2361 - auc_3: 0.9994 - val_loss: 2.3582 - val_accuracy: 0.1419 - val_auc_3: 0.8691\n",
            "Epoch 13/20\n",
            "304/304 [==============================] - 14s 48ms/step - loss: 0.0271 - accuracy: 0.2406 - auc_3: 0.9995 - val_loss: 2.4789 - val_accuracy: 0.1767 - val_auc_3: 0.8735\n",
            "Epoch 14/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0160 - accuracy: 0.2774 - auc_3: 0.9998 - val_loss: 2.6797 - val_accuracy: 0.1754 - val_auc_3: 0.8716\n",
            "Epoch 15/20\n",
            "304/304 [==============================] - 15s 48ms/step - loss: 0.0138 - accuracy: 0.2890 - auc_3: 0.9999 - val_loss: 2.9312 - val_accuracy: 0.2032 - val_auc_3: 0.8713\n",
            "Epoch 16/20\n",
            "240/304 [======================>.......] - ETA: 2s - loss: 0.0126 - accuracy: 0.3298 - auc_3: 0.9999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-f90795787341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-94-43ebc6502372>\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, generator, patience, MAX_EPOCHS, early_stop, val_split, decay_step, batch_size, initial_lr, lr_decay_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# history = model.fit(train_x, train_y, epochs=MAX_EPOCHS, batch_size = batch_size, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WqHLHazE5hS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJxUMGJNhHv",
        "outputId": "8afb9250-b0a0-4a5c-9281-92d1108fca53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(baseline, 'Baseline')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "608/608 [==============================] - 7s 11ms/step - loss: 0.0696 - accuracy: 0.0935 - auc_2: 0.9981\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 1.3836 - accuracy: 0.0659 - auc_2: 0.8915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RZWlUaV6kv"
      },
      "source": [
        "## AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVuV4gNXuZE",
        "outputId": "c9f6cbae-806a-4c5c-ce75-89fa8baaaeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "# Ref: https://github.com/Keyird/DeepLearning-TensorFlow2/blob/master/4.%20AlexNet/AlexNet.py\n",
        "Alex_layers=[\n",
        "    # layer 1\n",
        "    tf.keras.layers.Conv2D(48, kernel_size=11, strides=4, padding='same', activation='relu', input_shape=input_shape), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),  \n",
        "    # layer 2\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu'),  \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),  \n",
        "    # layer 3\n",
        "    tf.keras.layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu'), \n",
        "    # layer 4\n",
        "    tf.keras.layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    # layer 5\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # layer 6\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    # layer 7\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    # layer 8\n",
        "    tf.keras.layers.Dense(num_class)\n",
        "]\n",
        "\n",
        "AlexNet=tf.keras.Sequential(Alex_layers)\n",
        "AlexNet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 48)        17472     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 27, 27, 128)       153728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 192)       221376    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 192)       331968    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 128)       221312    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              4719616   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 5,797,059\n",
            "Trainable params: 5,797,059\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn2WDOI1YdyZ",
        "outputId": "d836bd23-1a8d-4ae7-dea6-ce9ba84418fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = compile_and_fit(AlexNet)\n",
        "\n",
        "train_performance['AlexNet'] = AlexNet.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['AlexNet'] = AlexNet.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['AlexNet'] = AlexNet.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.0288 - accuracy: 0.1418 - val_loss: 1.1287 - val_accuracy: 0.1545\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.2704 - accuracy: 0.1551 - val_loss: 1.5352 - val_accuracy: 0.1626\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.9998 - accuracy: 0.1398 - val_loss: 1.1170 - val_accuracy: 0.1748\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.0172 - accuracy: 0.1561 - val_loss: 1.0274 - val_accuracy: 0.1992\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0775 - accuracy: 0.1490 - val_loss: 1.5887 - val_accuracy: 0.1789\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.7334 - accuracy: 0.2041 - val_loss: 1.1982 - val_accuracy: 0.2114\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.1290 - accuracy: 0.2153 - val_loss: 1.0442 - val_accuracy: 0.2114\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0304 - accuracy: 0.1990 - val_loss: 1.0337 - val_accuracy: 0.1829\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.0194 - accuracy: 0.1704 - val_loss: 1.0084 - val_accuracy: 0.1707\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.9459 - accuracy: 0.1541 - val_loss: 1.2755 - val_accuracy: 0.1585\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0321 - accuracy: 0.1439 - val_loss: 1.1483 - val_accuracy: 0.1748\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.0000 - accuracy: 0.1357 - val_loss: 1.5355 - val_accuracy: 0.1789\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.3133 - accuracy: 0.1837 - val_loss: 1.0577 - val_accuracy: 0.1911\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.9909 - accuracy: 0.1673 - val_loss: 1.0785 - val_accuracy: 0.1829\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0279 - accuracy: 0.1612 - val_loss: 0.9641 - val_accuracy: 0.1423\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.9497 - accuracy: 0.1551 - val_loss: 1.0132 - val_accuracy: 0.1504\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.9200 - accuracy: 0.1398 - val_loss: 1.0670 - val_accuracy: 0.1545\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.2782 - accuracy: 0.1327 - val_loss: 1.6713 - val_accuracy: 0.1829\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 4.7552 - accuracy: 0.2092 - val_loss: 2.0789 - val_accuracy: 0.2602\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 1.3595 - accuracy: 0.3388 - val_loss: 1.0890 - val_accuracy: 0.4146\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 1.1251 - accuracy: 0.4102 - val_loss: 1.0905 - val_accuracy: 0.4146\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.0882 - accuracy: 0.4071 - val_loss: 1.0892 - val_accuracy: 0.4146\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0954 - accuracy: 0.4214 - val_loss: 1.0846 - val_accuracy: 0.4146\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.0852 - accuracy: 0.4245 - val_loss: 1.0842 - val_accuracy: 0.4146\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0851 - accuracy: 0.4163 - val_loss: 1.0838 - val_accuracy: 0.4146\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 1.0808 - accuracy: 0.4143 - val_loss: 1.0833 - val_accuracy: 0.4146\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0910 - accuracy: 0.4245 - val_loss: 1.0844 - val_accuracy: 0.4146\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.0674 - accuracy: 0.4245 - val_loss: 1.0830 - val_accuracy: 0.4146\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.0837 - accuracy: 0.4204 - val_loss: 1.0832 - val_accuracy: 0.4146\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.0854 - accuracy: 0.4255 - val_loss: 1.0824 - val_accuracy: 0.4146\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0772 - accuracy: 0.4316\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0824 - accuracy: 0.4146\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0686 - accuracy: 0.4589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_HXuHwc_vsP"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRwn7WkCE89Q"
      },
      "source": [
        "### VGG11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSdZflx_bnz-",
        "outputId": "1e5678a0-1dc7-4f16-b4c1-50f38b20abcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# Ref: https://github.com/Keyird/DeepLearning-TensorFlow2/blob/master/5.%20VGG11/VGG11.py\n",
        "VGG11_layers=[\n",
        "    # layer 1\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape = input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    # layer 2\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    # layer 3\n",
        "    tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    # layer 4\n",
        "    tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    # layer 5\n",
        "    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    # layer 6\n",
        "    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    # layer 7\n",
        "    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    # layer 8\n",
        "    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # layer 9\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    # layer 10\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    # layer 11\n",
        "    tf.keras.layers.Dense(num_class, activation='softmax')\n",
        "]\n",
        "\n",
        "VGG11=tf.keras.Sequential(VGG11_layers)\n",
        "VGG11.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 35,043,203\n",
            "Trainable params: 35,043,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5qIVx8bn8A",
        "outputId": "3df30a8a-6148-4027-98e9-0fa338c08937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = compile_and_fit(VGG11)\n",
        "\n",
        "train_performance['VGG11'] = VGG11.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['VGG11'] = VGG11.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['VGG11'] = VGG11.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 2/16 [==>...........................] - ETA: 4s - loss: 0.0760 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1253s vs `on_train_batch_end` time: 0.2565s). Check your callbacks.\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 0.1085 - accuracy: 0.9633 - val_loss: 1.1917 - val_accuracy: 0.8008\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 1.2009 - val_accuracy: 0.7683\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 1.3640 - val_accuracy: 0.7724\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0778 - accuracy: 0.9816 - val_loss: 1.5804 - val_accuracy: 0.7195\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0628 - accuracy: 0.9827 - val_loss: 1.4561 - val_accuracy: 0.7154\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.1000 - accuracy: 0.9755 - val_loss: 1.3159 - val_accuracy: 0.7317\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 1.2564 - val_accuracy: 0.7358\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 1.6064 - val_accuracy: 0.6992\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.1004 - accuracy: 0.9765 - val_loss: 1.4293 - val_accuracy: 0.7114\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 1.7592 - val_accuracy: 0.7480\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 1.5299 - val_accuracy: 0.7398\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.1235 - accuracy: 0.9663 - val_loss: 1.8042 - val_accuracy: 0.7033\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.9067 - val_accuracy: 0.7642\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 1.2510 - val_accuracy: 0.7398\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0116 - accuracy: 0.9949 - val_loss: 1.1667 - val_accuracy: 0.7683\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 1.4824 - val_accuracy: 0.7602\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 1.4895 - val_accuracy: 0.7602\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 1.5754 - val_accuracy: 0.7683\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.1020 - accuracy: 0.9724 - val_loss: 1.6105 - val_accuracy: 0.7154\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 1.4158 - val_accuracy: 0.7439\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 1.3986 - val_accuracy: 0.7358\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0437 - accuracy: 0.9898 - val_loss: 1.4904 - val_accuracy: 0.7236\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.0555 - accuracy: 0.9796 - val_loss: 2.2430 - val_accuracy: 0.6585\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.1050 - accuracy: 0.9776 - val_loss: 1.1562 - val_accuracy: 0.7439\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.0839 - accuracy: 0.9745 - val_loss: 1.7354 - val_accuracy: 0.7276\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 1.3091 - val_accuracy: 0.7480\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 1.2858 - val_accuracy: 0.7480\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 1.4026 - val_accuracy: 0.7520\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.0560 - accuracy: 0.9888 - val_loss: 1.5360 - val_accuracy: 0.6707\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 1.4603 - val_accuracy: 0.7398\n",
            "31/31 [==============================] - 2s 58ms/step - loss: 7.6826e-04 - accuracy: 1.0000\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.4603 - accuracy: 0.7398\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 3.5334 - accuracy: 0.5685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZzvKzJu8zkP"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG8C7sHa83po",
        "outputId": "16136d8e-4f5b-42cd-cac1-e375e443eba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# Ref: https://keras.io/api/applications/vgg/\n",
        "VGG16 = tf.keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling= max,\n",
        "    classes= num_class,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "VGG16.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 134,272,835\n",
            "Trainable params: 134,272,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifvLb3OZ8zO8",
        "outputId": "54febb5e-a583-483e-b0df-157a0e91e77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = compile_and_fit(VGG16)\n",
        "\n",
        "train_performance['VGG16'] = VGG16.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['VGG16'] = VGG16.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['VGG16'] = VGG16.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 2/16 [==>...........................] - ETA: 6s - loss: 8267.9902 - accuracy: 0.4922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2478s vs `on_train_batch_end` time: 0.5455s). Check your callbacks.\n",
            "16/16 [==============================] - 14s 898ms/step - loss: 1080.9412 - accuracy: 0.3653 - val_loss: 1.1003 - val_accuracy: 0.3293\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 13s 806ms/step - loss: 1.1446 - accuracy: 0.4000 - val_loss: 1.0875 - val_accuracy: 0.4187\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 13s 819ms/step - loss: 1.0858 - accuracy: 0.4306 - val_loss: 1.0825 - val_accuracy: 0.4146\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 13s 827ms/step - loss: 1.0786 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 13s 816ms/step - loss: 1.0757 - accuracy: 0.4316 - val_loss: 1.0907 - val_accuracy: 0.4146\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 13s 805ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0808 - val_accuracy: 0.4146\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 13s 805ms/step - loss: 1.0847 - accuracy: 0.4316 - val_loss: 1.0815 - val_accuracy: 0.4146\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 13s 807ms/step - loss: 1.0775 - accuracy: 0.4316 - val_loss: 1.0812 - val_accuracy: 0.4146\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 13s 810ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0811 - val_accuracy: 0.4146\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 13s 814ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0809 - val_accuracy: 0.4146\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0774 - accuracy: 0.4316 - val_loss: 1.0805 - val_accuracy: 0.4146\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 13s 813ms/step - loss: 1.0752 - accuracy: 0.4316 - val_loss: 1.0791 - val_accuracy: 0.4146\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 13s 807ms/step - loss: 1.0714 - accuracy: 0.4367 - val_loss: 1.0761 - val_accuracy: 0.4146\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 13s 812ms/step - loss: 1.0772 - accuracy: 0.4316 - val_loss: 1.0828 - val_accuracy: 0.4146\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 13s 806ms/step - loss: 1.0760 - accuracy: 0.4296 - val_loss: 1.0797 - val_accuracy: 0.4146\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0766 - accuracy: 0.4316 - val_loss: 1.0828 - val_accuracy: 0.4146\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0756 - accuracy: 0.4316 - val_loss: 1.0952 - val_accuracy: 0.4146\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 13s 807ms/step - loss: 1.0789 - accuracy: 0.4224 - val_loss: 1.0807 - val_accuracy: 0.4146\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 13s 808ms/step - loss: 1.0715 - accuracy: 0.4286 - val_loss: 1.0749 - val_accuracy: 0.4390\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0681 - accuracy: 0.4255 - val_loss: 1.0813 - val_accuracy: 0.4146\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0745 - accuracy: 0.4316 - val_loss: 1.0747 - val_accuracy: 0.4106\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 13s 810ms/step - loss: 1.0657 - accuracy: 0.4418 - val_loss: 1.0471 - val_accuracy: 0.4309\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 13s 810ms/step - loss: 1.0386 - accuracy: 0.4735 - val_loss: 1.0204 - val_accuracy: 0.4756\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 13s 812ms/step - loss: 1.0170 - accuracy: 0.5051 - val_loss: 0.9862 - val_accuracy: 0.4593\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 13s 808ms/step - loss: 1.0881 - accuracy: 0.4837 - val_loss: 1.0816 - val_accuracy: 0.4228\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 13s 809ms/step - loss: 1.0805 - accuracy: 0.4500 - val_loss: 1.0797 - val_accuracy: 0.4187\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 13s 807ms/step - loss: 1.0503 - accuracy: 0.4520 - val_loss: 1.1973 - val_accuracy: 0.2927\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 13s 811ms/step - loss: 1.1199 - accuracy: 0.3908 - val_loss: 1.0690 - val_accuracy: 0.4106\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 13s 812ms/step - loss: 1.1172 - accuracy: 0.4286 - val_loss: 1.0842 - val_accuracy: 0.4146\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 13s 811ms/step - loss: 1.0899 - accuracy: 0.4235 - val_loss: 1.0844 - val_accuracy: 0.4146\n",
            "31/31 [==============================] - 4s 121ms/step - loss: 1.0770 - accuracy: 0.4316\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 1.0844 - accuracy: 0.4146\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.0667 - accuracy: 0.4589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_pPK0lq9fNE"
      },
      "source": [
        "### VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykwB7ckD9hBG",
        "outputId": "46330e0f-4154-465e-d0e6-ea29b11d1a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Ref: https://keras.io/api/applications/vgg/\n",
        "VGG19 = tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling= max,\n",
        "    classes= num_class,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "VGG19.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 139,582,531\n",
            "Trainable params: 139,582,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPBZ2Oo9ttW",
        "outputId": "0f83fe55-7be2-4438-fdb5-53c58c7edce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = compile_and_fit(VGG19)\n",
        "\n",
        "train_performance['VGG19'] = VGG19.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['VGG19'] = VGG19.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['VGG19'] = VGG19.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 2/16 [==>...........................] - ETA: 11s - loss: 54836.3984 - accuracy: 0.3516WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3198s vs `on_train_batch_end` time: 0.6607s). Check your callbacks.\n",
            "16/16 [==============================] - 16s 984ms/step - loss: 7163.2656 - accuracy: 0.3602 - val_loss: 1.1120 - val_accuracy: 0.3252\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 15s 950ms/step - loss: 1.1383 - accuracy: 0.3908 - val_loss: 1.0788 - val_accuracy: 0.3496\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 15s 952ms/step - loss: 1.0814 - accuracy: 0.4255 - val_loss: 1.0767 - val_accuracy: 0.4146\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 16s 977ms/step - loss: 1.0884 - accuracy: 0.4316 - val_loss: 1.0889 - val_accuracy: 0.4146\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 15s 950ms/step - loss: 1.0898 - accuracy: 0.4316 - val_loss: 1.0864 - val_accuracy: 0.4146\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.0820 - accuracy: 0.4316 - val_loss: 1.0816 - val_accuracy: 0.4146\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 15s 951ms/step - loss: 1.0770 - accuracy: 0.4316 - val_loss: 1.0936 - val_accuracy: 0.4146\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 15s 948ms/step - loss: 1.0715 - accuracy: 0.4316 - val_loss: 1.0756 - val_accuracy: 0.4146\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 15s 954ms/step - loss: 1.0772 - accuracy: 0.4316 - val_loss: 1.0763 - val_accuracy: 0.4146\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 15s 948ms/step - loss: 1.0767 - accuracy: 0.4316 - val_loss: 1.0723 - val_accuracy: 0.4146\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 15s 944ms/step - loss: 1.0786 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 15s 949ms/step - loss: 1.0782 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 15s 953ms/step - loss: 1.0768 - accuracy: 0.4316 - val_loss: 1.0817 - val_accuracy: 0.4146\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 15s 951ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0809 - val_accuracy: 0.4146\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 15s 950ms/step - loss: 1.0760 - accuracy: 0.4316 - val_loss: 1.0781 - val_accuracy: 0.4146\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 15s 948ms/step - loss: 1.0774 - accuracy: 0.4276 - val_loss: 1.0809 - val_accuracy: 0.4146\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.0784 - accuracy: 0.4276 - val_loss: 1.0829 - val_accuracy: 0.4146\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 15s 946ms/step - loss: 1.0795 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 15s 941ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 15s 943ms/step - loss: 1.0763 - accuracy: 0.4316 - val_loss: 1.0816 - val_accuracy: 0.4146\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 15s 946ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0813 - val_accuracy: 0.4146\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.0768 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 15s 948ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 15s 945ms/step - loss: 1.0766 - accuracy: 0.4316 - val_loss: 1.0807 - val_accuracy: 0.4146\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.0798 - accuracy: 0.4316 - val_loss: 1.0806 - val_accuracy: 0.4146\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.1127 - accuracy: 0.4316 - val_loss: 1.0830 - val_accuracy: 0.4146\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 15s 948ms/step - loss: 1.0797 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 15s 946ms/step - loss: 1.0791 - accuracy: 0.4306 - val_loss: 1.0819 - val_accuracy: 0.4146\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 15s 946ms/step - loss: 1.0767 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 15s 947ms/step - loss: 1.0774 - accuracy: 0.4316 - val_loss: 1.0811 - val_accuracy: 0.4146\n",
            "31/31 [==============================] - 4s 144ms/step - loss: 1.0762 - accuracy: 0.4316\n",
            "8/8 [==============================] - 1s 129ms/step - loss: 1.0811 - accuracy: 0.4146\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.0680 - accuracy: 0.4589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9my4tlYcwUN"
      },
      "source": [
        "## GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbeaQO6fleFx",
        "outputId": "4f477a70-656b-4dcd-9f83-567624b0056b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# Ref: https://github.com/guaiguaibao/GoogLeNet_Tensorflow2.0/blob/master/tensorflow2.0/GoogLeNet/model.py\n",
        "def GoogLeNet(im_height=224, im_width=224, class_num=num_class, aux_logits=False):\n",
        "    input_image = layers.Input(shape= input_shape, dtype=\"float32\")\n",
        "    # (None, 224, 224, 3)\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"SAME\", activation=\"relu\", name=\"conv2d_1\")(input_image)\n",
        "    # (None, 112, 112, 64)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_1\")(x)\n",
        "    # (None, 56, 56, 64)\n",
        "    x = layers.Conv2D(64, kernel_size=1, activation=\"relu\", name=\"conv2d_2\")(x)\n",
        "    # (None, 56, 56, 64)\n",
        "    x = layers.Conv2D(192, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"conv2d_3\")(x)\n",
        "    # (None, 56, 56, 192)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_2\")(x)\n",
        "\n",
        "    # (None, 28, 28, 192)\n",
        "    x = Inception(64, 96, 128, 16, 32, 32, name=\"inception_3a\")(x)\n",
        "    # (None, 28, 28, 256)\n",
        "    x = Inception(128, 128, 192, 32, 96, 64, name=\"inception_3b\")(x)\n",
        "\n",
        "    # (None, 28, 28, 480)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_3\")(x)\n",
        "    # (None, 14, 14, 480)\n",
        "    x = Inception(192, 96, 208, 16, 48, 64, name=\"inception_4a\")(x)\n",
        "    if aux_logits:\n",
        "        aux1 = InceptionAux(class_num, name=\"aux_1\")(x)\n",
        "\n",
        "    # (None, 14, 14, 512)\n",
        "    x = Inception(160, 112, 224, 24, 64, 64, name=\"inception_4b\")(x)\n",
        "    # (None, 14, 14, 512)\n",
        "    x = Inception(128, 128, 256, 24, 64, 64, name=\"inception_4c\")(x)\n",
        "    # (None, 14, 14, 512)\n",
        "    x = Inception(112, 144, 288, 32, 64, 64, name=\"inception_4d\")(x)\n",
        "    if aux_logits:\n",
        "        aux2 = InceptionAux(class_num, name=\"aux_2\")(x)\n",
        "\n",
        "    # (None, 14, 14, 528)\n",
        "    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_4e\")(x)\n",
        "    # (None, 14, 14, 532)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_4\")(x)\n",
        "\n",
        "    # (None, 7, 7, 832)\n",
        "    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_5a\")(x)\n",
        "    # (None, 7, 7, 832)\n",
        "    x = Inception(384, 192, 384, 48, 128, 128, name=\"inception_5b\")(x)\n",
        "    # (None, 7, 7, 1024)\n",
        "    x = layers.AvgPool2D(pool_size=7, strides=1, name=\"avgpool_1\")(x)\n",
        "\n",
        "    # (None, 1, 1, 1024)\n",
        "    x = layers.Flatten(name=\"output_flatten\")(x)\n",
        "    # (None, 1024)\n",
        "    x = layers.Dropout(rate=0.4, name=\"output_dropout\")(x)\n",
        "    x = layers.Dense(class_num, name=\"output_dense\")(x)\n",
        "    # (None, class_num)\n",
        "    aux3 = layers.Softmax(name=\"aux_3\")(x)\n",
        "\n",
        "    if aux_logits:\n",
        "        model = models.Model(inputs=input_image, outputs=[aux1, aux2, aux3])\n",
        "    else:\n",
        "        model = models.Model(inputs=input_image, outputs=aux3)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Inception\n",
        "class Inception(layers.Layer):\n",
        "    def __init__(self, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, **kwargs):\n",
        "       \n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        self.branch1 = layers.Conv2D(ch1x1, kernel_size=1, activation=\"relu\")\n",
        "\n",
        "        self.branch2 = Sequential([\n",
        "            layers.Conv2D(ch3x3red, kernel_size=1, activation=\"relu\"),\n",
        "            layers.Conv2D(ch3x3, kernel_size=3, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n",
        "\n",
        "        self.branch3 = Sequential([\n",
        "            layers.Conv2D(ch5x5red, kernel_size=1, activation=\"relu\"),\n",
        "            layers.Conv2D(ch5x5, kernel_size=5, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n",
        "\n",
        "        self.branch4 = Sequential([\n",
        "            layers.MaxPool2D(pool_size=3, strides=1, padding=\"SAME\"),  # caution: default strides==pool_size\n",
        "            layers.Conv2D(pool_proj, kernel_size=1, activation=\"relu\")])                  # output_size= input_size\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        branch1 = self.branch1(inputs)\n",
        "        branch2 = self.branch2(inputs)\n",
        "        branch3 = self.branch3(inputs)\n",
        "        branch4 = self.branch4(inputs)\n",
        "        outputs = layers.concatenate([branch1, branch2, branch3, branch4])\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class InceptionAux(layers.Layer):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super(InceptionAux, self).__init__(**kwargs)\n",
        "        self.averagePool = layers.AvgPool2D(pool_size=5, strides=3)\n",
        "        self.conv = layers.Conv2D(128, kernel_size=1, activation=\"relu\")\n",
        "\n",
        "        self.fc1 = layers.Dense(1024, activation=\"relu\")\n",
        "        self.fc2 = layers.Dense(num_classes)\n",
        "        self.softmax = layers.Softmax()\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
        "        x = self.averagePool(inputs)\n",
        "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
        "        x = self.conv(x)\n",
        "        # N x 128 x 4 x 4\n",
        "        x = layers.Flatten()(x)\n",
        "        x = layers.Dropout(rate=0.5)(x)  \n",
        "        # N x 2048\n",
        "        x = self.fc1(x)\n",
        "        x = layers.Dropout(rate=0.5)(x)\n",
        "        # N x 1024\n",
        "        x = self.fc2(x)\n",
        "        # N x num_classes\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "GoogleNet_model = GoogLeNet(class_num = num_class)\n",
        "GoogleNet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 64)      9472      \n",
            "_________________________________________________________________\n",
            "maxpool_1 (MaxPooling2D)     (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 64)        4160      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 56, 56, 192)       110784    \n",
            "_________________________________________________________________\n",
            "maxpool_2 (MaxPooling2D)     (None, 28, 28, 192)       0         \n",
            "_________________________________________________________________\n",
            "inception_3a (Inception)     (None, 28, 28, 256)       163696    \n",
            "_________________________________________________________________\n",
            "inception_3b (Inception)     (None, 28, 28, 480)       388736    \n",
            "_________________________________________________________________\n",
            "maxpool_3 (MaxPooling2D)     (None, 14, 14, 480)       0         \n",
            "_________________________________________________________________\n",
            "inception_4a (Inception)     (None, 14, 14, 512)       376176    \n",
            "_________________________________________________________________\n",
            "inception_4b (Inception)     (None, 14, 14, 512)       449160    \n",
            "_________________________________________________________________\n",
            "inception_4c (Inception)     (None, 14, 14, 512)       510104    \n",
            "_________________________________________________________________\n",
            "inception_4d (Inception)     (None, 14, 14, 528)       605376    \n",
            "_________________________________________________________________\n",
            "inception_4e (Inception)     (None, 14, 14, 832)       868352    \n",
            "_________________________________________________________________\n",
            "maxpool_4 (MaxPooling2D)     (None, 7, 7, 832)         0         \n",
            "_________________________________________________________________\n",
            "inception_5a (Inception)     (None, 7, 7, 832)         1043456   \n",
            "_________________________________________________________________\n",
            "inception_5b (Inception)     (None, 7, 7, 1024)        1444080   \n",
            "_________________________________________________________________\n",
            "avgpool_1 (AveragePooling2D) (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "output_flatten (Flatten)     (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "output_dropout (Dropout)     (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "output_dense (Dense)         (None, 3)                 3075      \n",
            "_________________________________________________________________\n",
            "aux_3 (Softmax)              (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 5,976,627\n",
            "Trainable params: 5,976,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMyrz53JhBOy",
        "outputId": "5d1de344-c872-4261-d61d-33c79c764a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = compile_and_fit(GoogleNet_model)\n",
        "\n",
        "train_performance['GoogleNet_model'] = GoogleNet_model.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['GoogleNet_model'] = GoogleNet_model.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['GoogleNet_model'] = GoogleNet_model.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 2/16 [==>...........................] - ETA: 2s - loss: 1.5497 - accuracy: 0.5859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0808s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 1.0514 - accuracy: 0.5796 - val_loss: 0.8439 - val_accuracy: 0.6382\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.7843 - accuracy: 0.6347 - val_loss: 0.8312 - val_accuracy: 0.6260\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.7243 - accuracy: 0.6520 - val_loss: 0.7814 - val_accuracy: 0.6545\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.6915 - accuracy: 0.6816 - val_loss: 0.7177 - val_accuracy: 0.6667\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.6381 - accuracy: 0.7245 - val_loss: 0.7233 - val_accuracy: 0.6748\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6188 - accuracy: 0.7163 - val_loss: 0.6997 - val_accuracy: 0.7033\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.5923 - accuracy: 0.7439 - val_loss: 0.8003 - val_accuracy: 0.6748\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.5688 - accuracy: 0.7480 - val_loss: 0.7299 - val_accuracy: 0.6423\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.5453 - accuracy: 0.7602 - val_loss: 0.7147 - val_accuracy: 0.6992\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.5187 - accuracy: 0.7939 - val_loss: 0.7126 - val_accuracy: 0.7073\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.4845 - accuracy: 0.8041 - val_loss: 0.8132 - val_accuracy: 0.6748\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.5203 - accuracy: 0.7592 - val_loss: 0.7696 - val_accuracy: 0.6748\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.4278 - accuracy: 0.8255 - val_loss: 0.9036 - val_accuracy: 0.6748\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.4177 - accuracy: 0.8204 - val_loss: 0.8647 - val_accuracy: 0.6626\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.3881 - accuracy: 0.8541 - val_loss: 1.2226 - val_accuracy: 0.6098\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.4735 - accuracy: 0.7898 - val_loss: 0.8824 - val_accuracy: 0.6789\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.3428 - accuracy: 0.8602 - val_loss: 1.0364 - val_accuracy: 0.6789\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.3157 - accuracy: 0.8837 - val_loss: 0.9708 - val_accuracy: 0.6260\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.2429 - accuracy: 0.9082 - val_loss: 1.2393 - val_accuracy: 0.6545\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.2970 - accuracy: 0.8939 - val_loss: 1.0393 - val_accuracy: 0.6260\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.2841 - accuracy: 0.9031 - val_loss: 1.0627 - val_accuracy: 0.6789\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.2092 - accuracy: 0.9296 - val_loss: 1.3588 - val_accuracy: 0.6301\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.2031 - accuracy: 0.9276 - val_loss: 1.0562 - val_accuracy: 0.6951\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.1790 - accuracy: 0.9367 - val_loss: 2.5875 - val_accuracy: 0.6138\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.6290 - accuracy: 0.7612 - val_loss: 0.7395 - val_accuracy: 0.7033\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.3342 - accuracy: 0.8878 - val_loss: 0.9329 - val_accuracy: 0.6748\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.2673 - accuracy: 0.9000 - val_loss: 1.3811 - val_accuracy: 0.6341\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.3528 - accuracy: 0.8745 - val_loss: 1.0357 - val_accuracy: 0.6585\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.1499 - accuracy: 0.9561 - val_loss: 1.3027 - val_accuracy: 0.6382\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.1171 - accuracy: 0.9663 - val_loss: 1.7198 - val_accuracy: 0.6463\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1143 - accuracy: 0.9602\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.7198 - accuracy: 0.6463\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.6232 - accuracy: 0.6027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ERC8wjBrfV8"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKjK7rDFEzn"
      },
      "source": [
        "### Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfLi6yh2-4Hs"
      },
      "source": [
        "# Ref: https://keras.io/api/applications/resnet/\n",
        "ResNet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling= max,\n",
        "    classes= num_class,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "ResNet50.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i4zF7ZA-5Uf",
        "outputId": "c87ff630-5e6d-4f9a-da2d-787c5531a190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# history = compile_and_fit(ResNet50, base_generator)\n",
        "\n",
        "# train_performance['ResNet50'] = ResNet50.evaluate(train_x, train_y, verbose= 1)\n",
        "# val_performance['ResNet50'] = ResNet50.evaluate(val_x, val_y, verbose= 1)\n",
        "# # performance['ResNet50'] = ResNet50.evaluate(test_X, test_y, verbose= 1)\n",
        "\n",
        "history = compile_and_fit(ResNet50, data_augmentation_generator, MAX_EPOCHS=10)\n",
        "\n",
        "# train_performance['ResNet50WithAug'] = ResNet50.evaluate(train_x, train_y, verbose= 1)\n",
        "# val_performance['ResNet50WithAug'] = ResNet50.evaluate(val_x, val_y, verbose= 1)\n",
        "# performance['ResNet50WithAug'] = ResNet50.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 186s 610ms/step - loss: 0.4884 - accuracy: 0.7988\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 183s 604ms/step - loss: 0.4369 - accuracy: 0.8190\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 185s 608ms/step - loss: 0.4219 - accuracy: 0.8264\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 185s 609ms/step - loss: 0.4173 - accuracy: 0.8256\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 188s 620ms/step - loss: 0.3976 - accuracy: 0.8366\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 183s 603ms/step - loss: 0.3855 - accuracy: 0.8419\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 182s 599ms/step - loss: 0.3747 - accuracy: 0.8471\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 183s 603ms/step - loss: 0.3675 - accuracy: 0.8487\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 184s 604ms/step - loss: 0.3535 - accuracy: 0.8574\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 192s 631ms/step - loss: 0.3462 - accuracy: 0.8579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hHlQ9Ti50X",
        "outputId": "13619b6c-5595-49f6-d28b-22de1bcb3344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(ResNet50, \"ResNet50\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "608/608 [==============================] - 22s 36ms/step - loss: 0.3194 - accuracy: 0.8717\n",
            "152/152 [==============================] - 5s 36ms/step - loss: 0.3743 - accuracy: 0.8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psmsOlv-FIjx"
      },
      "source": [
        "### Resnet 152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD32-8U2-E4s",
        "outputId": "f89e815c-c99e-4601-ebb3-309fffbcd3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Ref: https://keras.io/api/applications/resnet/\n",
        "ResNet152 = tf.keras.applications.ResNet152(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling= max,\n",
        "    classes= num_class,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "ResNet152.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet152\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_37 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_relu (Activation (None, 28, 28, 128)  0           conv3_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_add (Add)          (None, 28, 28, 512)  0           conv3_block4_out[0][0]           \n",
            "                                                                 conv3_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_out (Activation)   (None, 28, 28, 512)  0           conv3_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_relu (Activation (None, 28, 28, 128)  0           conv3_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_add (Add)          (None, 28, 28, 512)  0           conv3_block5_out[0][0]           \n",
            "                                                                 conv3_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_out (Activation)   (None, 28, 28, 512)  0           conv3_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_relu (Activation (None, 28, 28, 128)  0           conv3_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_add (Add)          (None, 28, 28, 512)  0           conv3_block6_out[0][0]           \n",
            "                                                                 conv3_block7_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_out (Activation)   (None, 28, 28, 512)  0           conv3_block7_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_relu (Activation (None, 28, 28, 128)  0           conv3_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_add (Add)          (None, 28, 28, 512)  0           conv3_block7_out[0][0]           \n",
            "                                                                 conv3_block8_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_out (Activation)   (None, 28, 28, 512)  0           conv3_block8_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_add (Add)         (None, 14, 14, 1024) 0           conv4_block23_out[0][0]          \n",
            "                                                                 conv4_block24_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_out (Activation)  (None, 14, 14, 1024) 0           conv4_block24_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block24_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block25_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_add (Add)         (None, 14, 14, 1024) 0           conv4_block24_out[0][0]          \n",
            "                                                                 conv4_block25_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_out (Activation)  (None, 14, 14, 1024) 0           conv4_block25_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block25_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block26_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_add (Add)         (None, 14, 14, 1024) 0           conv4_block25_out[0][0]          \n",
            "                                                                 conv4_block26_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_out (Activation)  (None, 14, 14, 1024) 0           conv4_block26_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block26_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block27_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_add (Add)         (None, 14, 14, 1024) 0           conv4_block26_out[0][0]          \n",
            "                                                                 conv4_block27_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_out (Activation)  (None, 14, 14, 1024) 0           conv4_block27_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block27_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block28_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_add (Add)         (None, 14, 14, 1024) 0           conv4_block27_out[0][0]          \n",
            "                                                                 conv4_block28_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_out (Activation)  (None, 14, 14, 1024) 0           conv4_block28_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block28_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block29_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_add (Add)         (None, 14, 14, 1024) 0           conv4_block28_out[0][0]          \n",
            "                                                                 conv4_block29_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_out (Activation)  (None, 14, 14, 1024) 0           conv4_block29_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block29_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block30_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_add (Add)         (None, 14, 14, 1024) 0           conv4_block29_out[0][0]          \n",
            "                                                                 conv4_block30_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_out (Activation)  (None, 14, 14, 1024) 0           conv4_block30_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block30_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block31_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_add (Add)         (None, 14, 14, 1024) 0           conv4_block30_out[0][0]          \n",
            "                                                                 conv4_block31_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_out (Activation)  (None, 14, 14, 1024) 0           conv4_block31_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block31_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block32_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_add (Add)         (None, 14, 14, 1024) 0           conv4_block31_out[0][0]          \n",
            "                                                                 conv4_block32_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_out (Activation)  (None, 14, 14, 1024) 0           conv4_block32_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block32_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block33_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_add (Add)         (None, 14, 14, 1024) 0           conv4_block32_out[0][0]          \n",
            "                                                                 conv4_block33_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_out (Activation)  (None, 14, 14, 1024) 0           conv4_block33_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block33_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block34_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_add (Add)         (None, 14, 14, 1024) 0           conv4_block33_out[0][0]          \n",
            "                                                                 conv4_block34_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_out (Activation)  (None, 14, 14, 1024) 0           conv4_block34_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block34_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block35_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_add (Add)         (None, 14, 14, 1024) 0           conv4_block34_out[0][0]          \n",
            "                                                                 conv4_block35_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_out (Activation)  (None, 14, 14, 1024) 0           conv4_block35_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block36_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_add (Add)         (None, 14, 14, 1024) 0           conv4_block35_out[0][0]          \n",
            "                                                                 conv4_block36_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_out (Activation)  (None, 14, 14, 1024) 0           conv4_block36_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 3)            6147        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 58,377,091\n",
            "Trainable params: 58,225,667\n",
            "Non-trainable params: 151,424\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO5y8vy5t52s",
        "outputId": "fbe0f173-db78-49bd-b99c-209e295eb63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "# out of meomery \n",
        "history = compile_and_fit(ResNet152)\n",
        "\n",
        "train_performance['ResNet152'] = ResNet152.evaluate(train_x, train_y, verbose= 1)\n",
        "val_performance['ResNet152'] = ResNet152.evaluate(val_x, val_y, verbose= 1)\n",
        "performance['ResNet152'] = ResNet152.evaluate(test_X, test_y, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-240-83f412dd48c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet152\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-209-14c910bc6e56>\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, patience, MAX_EPOCHS, early_stop, val_split, decay_step, batch_size, initial_lr, lr_decay_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,256,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet101/conv2_block3_3_bn/FusedBatchNormV3 (defined at <ipython-input-209-14c910bc6e56>:14) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_415347]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI0ADIcekiWI"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_usOI8eHnVio",
        "outputId": "80497a5f-3058-4c3a-f93a-9f1a2c749084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(\n",
        "    weights=\"imagenet\",\n",
        "    include_top = False,\n",
        "    input_shape=input_shape\n",
        ")\n",
        "\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.layers[-1].output)\n",
        "outputs = tf.keras.layers.Dense(num_class, activation = tf.keras.activations.softmax)(x)\n",
        "\n",
        "tl_model = tf.keras.Model(inputs = base_model.inputs, outputs = outputs)\n",
        "print(len(tl_model.layers))\n",
        "for i in range(0, 150):\n",
        "  tl_model.layers[i].trainable = False\n",
        "\n",
        "tl_model.summary(line_length= 200)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "177\n",
            "Model: \"functional_44\"\n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
            "========================================================================================================================================================================================================\n",
            "input_35 (InputLayer)                                             [(None, 224, 224, 3)]                       0                                                                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)                                         (None, 230, 230, 3)                         0                       input_35[0][0]                                                    \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)                                               (None, 112, 112, 64)                        9472                    conv1_pad[0][0]                                                   \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)                                     (None, 112, 112, 64)                        256                     conv1_conv[0][0]                                                  \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv1_relu (Activation)                                           (None, 112, 112, 64)                        0                       conv1_bn[0][0]                                                    \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)                                         (None, 114, 114, 64)                        0                       conv1_relu[0][0]                                                  \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)                                         (None, 56, 56, 64)                          0                       pool1_pad[0][0]                                                   \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)                                      (None, 56, 56, 64)                          4160                    pool1_pool[0][0]                                                  \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block1_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block1_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)                                      (None, 56, 56, 64)                          36928                   conv2_block1_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block1_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block1_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)                                      (None, 56, 56, 256)                         16640                   pool1_pool[0][0]                                                  \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)                                      (None, 56, 56, 256)                         16640                   conv2_block1_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormalization)                            (None, 56, 56, 256)                         1024                    conv2_block1_0_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormalization)                            (None, 56, 56, 256)                         1024                    conv2_block1_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)                                            (None, 56, 56, 256)                         0                       conv2_block1_0_bn[0][0]                                           \n",
            "                                                                                                                                      conv2_block1_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)                                     (None, 56, 56, 256)                         0                       conv2_block1_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)                                      (None, 56, 56, 64)                          16448                   conv2_block1_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block2_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block2_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)                                      (None, 56, 56, 64)                          36928                   conv2_block2_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block2_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block2_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)                                      (None, 56, 56, 256)                         16640                   conv2_block2_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormalization)                            (None, 56, 56, 256)                         1024                    conv2_block2_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)                                            (None, 56, 56, 256)                         0                       conv2_block1_out[0][0]                                            \n",
            "                                                                                                                                      conv2_block2_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)                                     (None, 56, 56, 256)                         0                       conv2_block2_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)                                      (None, 56, 56, 64)                          16448                   conv2_block2_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block3_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block3_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)                                      (None, 56, 56, 64)                          36928                   conv2_block3_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormalization)                            (None, 56, 56, 64)                          256                     conv2_block3_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation)                                  (None, 56, 56, 64)                          0                       conv2_block3_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)                                      (None, 56, 56, 256)                         16640                   conv2_block3_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormalization)                            (None, 56, 56, 256)                         1024                    conv2_block3_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)                                            (None, 56, 56, 256)                         0                       conv2_block2_out[0][0]                                            \n",
            "                                                                                                                                      conv2_block3_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)                                     (None, 56, 56, 256)                         0                       conv2_block3_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)                                      (None, 28, 28, 128)                         32896                   conv2_block3_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block1_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block1_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)                                      (None, 28, 28, 128)                         147584                  conv3_block1_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block1_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block1_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)                                      (None, 28, 28, 512)                         131584                  conv2_block3_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)                                      (None, 28, 28, 512)                         66048                   conv3_block1_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormalization)                            (None, 28, 28, 512)                         2048                    conv3_block1_0_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormalization)                            (None, 28, 28, 512)                         2048                    conv3_block1_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)                                            (None, 28, 28, 512)                         0                       conv3_block1_0_bn[0][0]                                           \n",
            "                                                                                                                                      conv3_block1_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)                                     (None, 28, 28, 512)                         0                       conv3_block1_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)                                      (None, 28, 28, 128)                         65664                   conv3_block1_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block2_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block2_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)                                      (None, 28, 28, 128)                         147584                  conv3_block2_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block2_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block2_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)                                      (None, 28, 28, 512)                         66048                   conv3_block2_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormalization)                            (None, 28, 28, 512)                         2048                    conv3_block2_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)                                            (None, 28, 28, 512)                         0                       conv3_block1_out[0][0]                                            \n",
            "                                                                                                                                      conv3_block2_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)                                     (None, 28, 28, 512)                         0                       conv3_block2_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)                                      (None, 28, 28, 128)                         65664                   conv3_block2_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block3_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block3_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)                                      (None, 28, 28, 128)                         147584                  conv3_block3_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block3_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block3_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)                                      (None, 28, 28, 512)                         66048                   conv3_block3_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormalization)                            (None, 28, 28, 512)                         2048                    conv3_block3_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)                                            (None, 28, 28, 512)                         0                       conv3_block2_out[0][0]                                            \n",
            "                                                                                                                                      conv3_block3_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)                                     (None, 28, 28, 512)                         0                       conv3_block3_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)                                      (None, 28, 28, 128)                         65664                   conv3_block3_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block4_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block4_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)                                      (None, 28, 28, 128)                         147584                  conv3_block4_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormalization)                            (None, 28, 28, 128)                         512                     conv3_block4_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation)                                  (None, 28, 28, 128)                         0                       conv3_block4_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)                                      (None, 28, 28, 512)                         66048                   conv3_block4_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormalization)                            (None, 28, 28, 512)                         2048                    conv3_block4_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)                                            (None, 28, 28, 512)                         0                       conv3_block3_out[0][0]                                            \n",
            "                                                                                                                                      conv3_block4_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)                                     (None, 28, 28, 512)                         0                       conv3_block4_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)                                      (None, 14, 14, 256)                         131328                  conv3_block4_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block1_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block1_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block1_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block1_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block1_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)                                      (None, 14, 14, 1024)                        525312                  conv3_block4_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block1_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block1_0_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block1_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block1_0_bn[0][0]                                           \n",
            "                                                                                                                                      conv4_block1_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block1_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)                                      (None, 14, 14, 256)                         262400                  conv4_block1_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block2_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block2_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block2_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block2_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block2_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block2_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block2_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block1_out[0][0]                                            \n",
            "                                                                                                                                      conv4_block2_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block2_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)                                      (None, 14, 14, 256)                         262400                  conv4_block2_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block3_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block3_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block3_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block3_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block3_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block3_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block3_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block2_out[0][0]                                            \n",
            "                                                                                                                                      conv4_block3_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block3_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)                                      (None, 14, 14, 256)                         262400                  conv4_block3_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block4_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block4_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block4_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block4_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block4_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block4_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block4_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block3_out[0][0]                                            \n",
            "                                                                                                                                      conv4_block4_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block4_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)                                      (None, 14, 14, 256)                         262400                  conv4_block4_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block5_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block5_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block5_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block5_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block5_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block5_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block5_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block4_out[0][0]                                            \n",
            "                                                                                                                                      conv4_block5_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block5_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)                                      (None, 14, 14, 256)                         262400                  conv4_block5_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block6_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block6_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)                                      (None, 14, 14, 256)                         590080                  conv4_block6_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormalization)                            (None, 14, 14, 256)                         1024                    conv4_block6_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation)                                  (None, 14, 14, 256)                         0                       conv4_block6_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)                                      (None, 14, 14, 1024)                        263168                  conv4_block6_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormalization)                            (None, 14, 14, 1024)                        4096                    conv4_block6_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)                                            (None, 14, 14, 1024)                        0                       conv4_block5_out[0][0]                                            \n",
            "                                                                                                                                      conv4_block6_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)                                     (None, 14, 14, 1024)                        0                       conv4_block6_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)                                      (None, 7, 7, 512)                           524800                  conv4_block6_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block1_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block1_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)                                      (None, 7, 7, 512)                           2359808                 conv5_block1_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block1_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block1_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)                                      (None, 7, 7, 2048)                          2099200                 conv4_block6_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)                                      (None, 7, 7, 2048)                          1050624                 conv5_block1_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormalization)                            (None, 7, 7, 2048)                          8192                    conv5_block1_0_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormalization)                            (None, 7, 7, 2048)                          8192                    conv5_block1_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)                                            (None, 7, 7, 2048)                          0                       conv5_block1_0_bn[0][0]                                           \n",
            "                                                                                                                                      conv5_block1_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)                                     (None, 7, 7, 2048)                          0                       conv5_block1_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)                                      (None, 7, 7, 512)                           1049088                 conv5_block1_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block2_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block2_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)                                      (None, 7, 7, 512)                           2359808                 conv5_block2_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block2_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block2_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)                                      (None, 7, 7, 2048)                          1050624                 conv5_block2_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormalization)                            (None, 7, 7, 2048)                          8192                    conv5_block2_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)                                            (None, 7, 7, 2048)                          0                       conv5_block1_out[0][0]                                            \n",
            "                                                                                                                                      conv5_block2_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)                                     (None, 7, 7, 2048)                          0                       conv5_block2_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)                                      (None, 7, 7, 512)                           1049088                 conv5_block2_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block3_1_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block3_1_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)                                      (None, 7, 7, 512)                           2359808                 conv5_block3_1_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormalization)                            (None, 7, 7, 512)                           2048                    conv5_block3_2_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation)                                  (None, 7, 7, 512)                           0                       conv5_block3_2_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)                                      (None, 7, 7, 2048)                          1050624                 conv5_block3_2_relu[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormalization)                            (None, 7, 7, 2048)                          8192                    conv5_block3_3_conv[0][0]                                         \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)                                            (None, 7, 7, 2048)                          0                       conv5_block2_out[0][0]                                            \n",
            "                                                                                                                                      conv5_block3_3_bn[0][0]                                           \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)                                     (None, 7, 7, 2048)                          0                       conv5_block3_add[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "global_average_pooling2d_25 (GlobalAveragePooling2D)              (None, 2048)                                0                       conv5_block3_out[0][0]                                            \n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "dense_24 (Dense)                                                  (None, 3)                                   6147                    global_average_pooling2d_25[0][0]                                 \n",
            "========================================================================================================================================================================================================\n",
            "Total params: 23,593,859\n",
            "Trainable params: 9,996,291\n",
            "Non-trainable params: 13,597,568\n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyQqPFRTsgoV",
        "outputId": "4a2e8cf6-f161-430a-e12e-51daaf55ee92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = compile_and_fit(tl_model, base_generator, MAX_EPOCHS=10)\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.2319 - accuracy: 0.9157\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 26s 85ms/step - loss: 0.1342 - accuracy: 0.9507\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.0804 - accuracy: 0.9715\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.0453 - accuracy: 0.9860\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.0331 - accuracy: 0.9903\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 26s 85ms/step - loss: 0.0202 - accuracy: 0.9943\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.0128 - accuracy: 0.9969\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 26s 84ms/step - loss: 0.0080 - accuracy: 0.9983\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 26s 85ms/step - loss: 0.0051 - accuracy: 0.9989\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 26s 85ms/step - loss: 0.0082 - accuracy: 0.9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzE71ge-yoUR",
        "outputId": "a99a3288-9dda-4cc6-9bcb-2c04b267e3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(tl_model, \"Transfer Learning\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "608/608 [==============================] - 22s 36ms/step - loss: 0.0074 - accuracy: 0.9979\n",
            "152/152 [==============================] - 6s 37ms/step - loss: 0.3289 - accuracy: 0.9272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQmHYvO-1jgd",
        "outputId": "af747bf7-fbe9-4bce-b706-77a66ec36806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = compile_and_fit(tl_model, data_augmentation_generator, MAX_EPOCHS=10)\n",
        "evaluate_model(tl_model, \"TL + AUG\")  "
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 195s 642ms/step - loss: 0.1294 - accuracy: 0.9528\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 193s 634ms/step - loss: 0.0913 - accuracy: 0.9671\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 192s 632ms/step - loss: 0.0707 - accuracy: 0.9752\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 187s 616ms/step - loss: 0.0589 - accuracy: 0.9791\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 187s 614ms/step - loss: 0.0494 - accuracy: 0.9827\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 183s 601ms/step - loss: 0.0418 - accuracy: 0.9853\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 183s 601ms/step - loss: 0.0311 - accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 184s 605ms/step - loss: 0.0294 - accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 184s 604ms/step - loss: 0.0269 - accuracy: 0.9910\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 185s 608ms/step - loss: 0.0192 - accuracy: 0.9941\n",
            "608/608 [==============================] - 22s 36ms/step - loss: 0.0061 - accuracy: 0.9983\n",
            "152/152 [==============================] - 6s 36ms/step - loss: 0.2868 - accuracy: 0.9338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVc7J3G-dseB"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyaIO-565Viy"
      },
      "source": [
        "x = np.arange(len(train_performance))\n",
        "width = 0.2\n",
        "\n",
        "\n",
        "def generate_metric_plt(metric_name):\n",
        "  metric_index = ResNet50.metrics_names.index(metric_name)\n",
        "  train_acc = [v[metric_index] for _, v in sorted(train_performance.items(), key = lambda x: x[0])]\n",
        "  val_acc = [v[metric_index] for _, v in sorted(val_performance.items(), key = lambda x: x[0])]\n",
        "  # test_acc = [v[metric_index] for v in performance.values()]\n",
        "  print(val_performance)\n",
        "  print(train_performance)\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.bar(x - 0.23, train_acc, width, label='Training')\n",
        "  plt.bar(x, val_acc, width, label='Validation')\n",
        "  plt.xticks(ticks=x, labels=sorted(train_performance.keys()),\n",
        "            rotation=45)\n",
        "  plt.ylabel(metric_name)\n",
        "  _ = plt.legend()\n",
        "  return plt"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFXQQyNPkhsU",
        "outputId": "351616f0-2e5d-4923-ed41-3ab03fca55bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "source": [
        "generate_metric_plt('accuracy')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Baseline': [1.3835515975952148, 0.06588509678840637, 0.8914709687232971], 'ResNet50': [0.37425974011421204, 0.8469765782356262], 'Transfer Learning': [0.3288501501083374, 0.9271904826164246], 'TL + AUG': [0.2867913246154785, 0.933772087097168]}\n",
            "{'Baseline': [0.06956971436738968, 0.09346771240234375, 0.9981369376182556], 'ResNet50': [0.3193565011024475, 0.8716511726379395], 'Transfer Learning': [0.0074171950109303, 0.9978917241096497], 'TL + AUG': [0.006147296633571386, 0.9983030557632446]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlvLsI27kkyt",
        "outputId": "9e42334b-9dd0-4c50-9adf-2f0a98a12e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "generate_metric_plt('auc_2')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-44a188a9f6b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_metric_plt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-102-f6b408a59441>\u001b[0m in \u001b[0;36mgenerate_metric_plt\u001b[0;34m(metric_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_metric_plt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmetric_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'auc_2' is not in list"
          ]
        }
      ]
    }
  ]
}