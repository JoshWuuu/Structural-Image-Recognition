{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS230_Project.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMFN77IXNRfEnc4GKmjhvRx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YTTJ-J9R-0Ap"},"source":["# Setting"]},{"cell_type":"code","metadata":{"id":"-Lf7m3fY7RJJ","executionInfo":{"status":"ok","timestamp":1602716787018,"user_tz":420,"elapsed":339,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"5519e50c-e77f-4e3f-999a-b7df442d48a4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6QW3BH1m-iZ6","executionInfo":{"status":"ok","timestamp":1602741577450,"user_tz":420,"elapsed":375,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from keras.layers.convolutional import Conv2D\n","from keras.layers import Flatten,BatchNormalization\n","from keras.layers.merge import add\n","from keras.models import Sequential\n","from keras.layers import Input, merge, ZeroPadding2D\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.layers.convolutional import Convolution2D\n","from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.regularizers import l2\n","from keras.models import Model"],"execution_count":215,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eo-9p3bk-5V3"},"source":["# Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"ASdNdMJq-90Y","executionInfo":{"status":"ok","timestamp":1602741143551,"user_tz":420,"elapsed":1612,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}}},"source":["file_path = '/content/drive/My Drive/CS230/task5/task5_X_train.npy'\n","train_x_w = np.load(file_path)\n","np.random.seed(1)\n","np.random.shuffle(train_x_w)"],"execution_count":206,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NTbDJEx_jbi","executionInfo":{"status":"ok","timestamp":1602741143552,"user_tz":420,"elapsed":828,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}}},"source":["file_path = '/content/drive/My Drive/CS230/task5/task5_y_train.npy'\n","train_y_w = np.load(file_path)\n","np.random.seed(1)\n","np.random.shuffle(train_y_w)"],"execution_count":207,"outputs":[]},{"cell_type":"code","metadata":{"id":"LK5NCro2wVpb"},"source":["index = 601 \n","train_x_w[index] += 80\n","print(train_x_w[index])\n","plt.imshow(train_x_w[index].astype('uint8'))\n","print (\"y = \" + str(train_y_w[index]))\n","train_x_w[index] -= 80"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Jd17o0T3vLS","executionInfo":{"status":"ok","timestamp":1602741149902,"user_tz":420,"elapsed":325,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}}},"source":["n = len(train_x_w)\n","train_x = train_x_w[0:int(n*0.8)]\n","val_x = train_x_w[int(n*0.8):]\n","train_y = train_y_w[0:int(n*0.8)]\n","val_y = train_y_w[int(n*0.8):]"],"execution_count":208,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBpzkxEnADl4"},"source":["file_path = '/content/drive/My Drive/CS230/task5/task5_X_test.npy'\n","test_X = np.load(file_path)\n","test_X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Rn99wCNADw4"},"source":["file_path = '/content/drive/My Drive/CS230/task5/task5_y_test.npy'\n","test_y = np.load(file_path)\n","test_y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ho3dneuN_s5i"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"yQCCo1MkIadG","executionInfo":{"status":"ok","timestamp":1602741151974,"user_tz":420,"elapsed":405,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}}},"source":["def compile_and_fit(model, patience=2, MAX_EPOCHS = 30, early_stop = False, val_split = 0.1, decay_step = 500,\n","                    batch_size = 64, initial_lr = 1e-3, lr_decay_rate = 0.9):\n","\n","  lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate= initial_lr,\n","    decay_steps= decay_step,\n","    decay_rate= lr_decay_rate)\n","  \n","  model.compile(loss=tf.losses.categorical_crossentropy,\n","                optimizer=tf.optimizers.Adam(learning_rate= lr_schedule),\n","                metrics=['accuracy'])\n","  \n","  if (early_stop == False):\n","    history = model.fit(train_x, train_y, epochs=MAX_EPOCHS, batch_size = batch_size, validation_data = (val_x, val_y))\n","  else:\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                    patience=patience,\n","                                                    mode='min')\n","    history = model.fit(train_x, train_y, epochs=MAX_EPOCHS, batch_size = batch_size, validation_split = val_split, callbacks=[early_stopping])\n","\n","  return history"],"execution_count":209,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zef_2koUGMzc"},"source":["## Baseline"]},{"cell_type":"code","metadata":{"id":"XaUMoSjtJf6Z"},"source":["input_shape = train_x.shape[1:]\n","num_class = train_y.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMrgVUWnGSz6","executionInfo":{"status":"ok","timestamp":1602739930801,"user_tz":420,"elapsed":346,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"96853c46-f390-4c84-eb11-fef079a0eda7","colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["layers=[\n","    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",activation=tf.nn.relu,input_shape=input_shape),\n","    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","    \n","    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=tf.nn.relu),\n","    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","        \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=128,activation=tf.nn.relu),\n","    \n","    tf.keras.layers.Dense(units=num_class, activation=tf.nn.softmax)\n","]\n","\n","baseline=tf.keras.Sequential(layers)\n","baseline.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1142\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2467 (Conv2D)         (None, 224, 224, 32)      896       \n","_________________________________________________________________\n","max_pooling2d_340 (MaxPoolin (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv2d_2468 (Conv2D)         (None, 112, 112, 64)      18496     \n","_________________________________________________________________\n","max_pooling2d_341 (MaxPoolin (None, 56, 56, 64)        0         \n","_________________________________________________________________\n","flatten_11 (Flatten)         (None, 200704)            0         \n","_________________________________________________________________\n","dense_52 (Dense)             (None, 128)               25690240  \n","_________________________________________________________________\n","dense_53 (Dense)             (None, 3)                 387       \n","=================================================================\n","Total params: 25,710,019\n","Trainable params: 25,710,019\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KUeLC8BKGMRT","executionInfo":{"status":"ok","timestamp":1602741852474,"user_tz":420,"elapsed":44975,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"450f3432-bd1a-41cb-e71f-b69a37cf4a7a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(baseline)\n","\n","train_performance = {}\n","val_performance = {}\n","performance = {}\n","train_performance['Baseline'] = baseline.evaluate(train_x, train_y, verbose= 1)\n","val_performance['Baseline'] = baseline.evaluate(val_x, val_y, verbose= 1)\n","performance['Baseline'] = baseline.evaluate(test_X, test_y, verbose= 1)"],"execution_count":218,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 1s - loss: 2.5704e-07 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0404s vs `on_train_batch_end` time: 0.0674s). Check your callbacks.\n","16/16 [==============================] - 2s 99ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 6.9086 - val_accuracy: 0.3984\n","Epoch 2/30\n","16/16 [==============================] - 1s 86ms/step - loss: 0.0107 - accuracy: 0.9939 - val_loss: 9.2517 - val_accuracy: 0.4065\n","Epoch 3/30\n","16/16 [==============================] - 1s 87ms/step - loss: 0.1392 - accuracy: 0.9857 - val_loss: 11.8102 - val_accuracy: 0.3577\n","Epoch 4/30\n","16/16 [==============================] - 1s 86ms/step - loss: 0.0464 - accuracy: 0.9929 - val_loss: 6.5561 - val_accuracy: 0.3943\n","Epoch 5/30\n","16/16 [==============================] - 1s 87ms/step - loss: 0.0433 - accuracy: 0.9929 - val_loss: 7.1897 - val_accuracy: 0.3943\n","Epoch 6/30\n","16/16 [==============================] - 1s 89ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 6.2917 - val_accuracy: 0.3496\n","Epoch 7/30\n","16/16 [==============================] - 1s 87ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: 5.7194 - val_accuracy: 0.3577\n","Epoch 8/30\n","16/16 [==============================] - 1s 86ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 5.6528 - val_accuracy: 0.3618\n","Epoch 9/30\n","16/16 [==============================] - 1s 85ms/step - loss: 8.3085e-05 - accuracy: 1.0000 - val_loss: 5.7669 - val_accuracy: 0.3821\n","Epoch 10/30\n","16/16 [==============================] - 1s 86ms/step - loss: 2.9051e-05 - accuracy: 1.0000 - val_loss: 5.9642 - val_accuracy: 0.3943\n","Epoch 11/30\n","16/16 [==============================] - 1s 86ms/step - loss: 1.4442e-05 - accuracy: 1.0000 - val_loss: 6.0163 - val_accuracy: 0.3902\n","Epoch 12/30\n","16/16 [==============================] - 1s 86ms/step - loss: 8.2602e-06 - accuracy: 1.0000 - val_loss: 5.9974 - val_accuracy: 0.3862\n","Epoch 13/30\n","16/16 [==============================] - 1s 87ms/step - loss: 3.7259e-06 - accuracy: 1.0000 - val_loss: 6.0002 - val_accuracy: 0.3821\n","Epoch 14/30\n","16/16 [==============================] - 1s 88ms/step - loss: 2.6454e-06 - accuracy: 1.0000 - val_loss: 6.0421 - val_accuracy: 0.3780\n","Epoch 15/30\n","16/16 [==============================] - 1s 89ms/step - loss: 2.1144e-06 - accuracy: 1.0000 - val_loss: 6.0799 - val_accuracy: 0.3780\n","Epoch 16/30\n","16/16 [==============================] - 1s 86ms/step - loss: 1.5870e-06 - accuracy: 1.0000 - val_loss: 6.1151 - val_accuracy: 0.3780\n","Epoch 17/30\n","16/16 [==============================] - 1s 88ms/step - loss: 1.2926e-06 - accuracy: 1.0000 - val_loss: 6.1417 - val_accuracy: 0.3780\n","Epoch 18/30\n","16/16 [==============================] - 1s 90ms/step - loss: 1.0717e-06 - accuracy: 1.0000 - val_loss: 6.1658 - val_accuracy: 0.3821\n","Epoch 19/30\n","16/16 [==============================] - 1s 87ms/step - loss: 9.4150e-07 - accuracy: 1.0000 - val_loss: 6.1891 - val_accuracy: 0.3821\n","Epoch 20/30\n","16/16 [==============================] - 1s 88ms/step - loss: 7.8681e-07 - accuracy: 1.0000 - val_loss: 6.2226 - val_accuracy: 0.3821\n","Epoch 21/30\n","16/16 [==============================] - 1s 89ms/step - loss: 6.7419e-07 - accuracy: 1.0000 - val_loss: 6.2472 - val_accuracy: 0.3862\n","Epoch 22/30\n","16/16 [==============================] - 1s 87ms/step - loss: 5.8395e-07 - accuracy: 1.0000 - val_loss: 6.2672 - val_accuracy: 0.3862\n","Epoch 23/30\n","16/16 [==============================] - 1s 88ms/step - loss: 5.1694e-07 - accuracy: 1.0000 - val_loss: 6.2835 - val_accuracy: 0.3821\n","Epoch 24/30\n","16/16 [==============================] - 1s 88ms/step - loss: 4.7193e-07 - accuracy: 1.0000 - val_loss: 6.3003 - val_accuracy: 0.3821\n","Epoch 25/30\n","16/16 [==============================] - 1s 89ms/step - loss: 4.1112e-07 - accuracy: 1.0000 - val_loss: 6.3144 - val_accuracy: 0.3821\n","Epoch 26/30\n","16/16 [==============================] - 1s 89ms/step - loss: 3.7561e-07 - accuracy: 1.0000 - val_loss: 6.3265 - val_accuracy: 0.3821\n","Epoch 27/30\n","16/16 [==============================] - 1s 89ms/step - loss: 3.3839e-07 - accuracy: 1.0000 - val_loss: 6.3403 - val_accuracy: 0.3821\n","Epoch 28/30\n","16/16 [==============================] - 1s 89ms/step - loss: 3.0835e-07 - accuracy: 1.0000 - val_loss: 6.3512 - val_accuracy: 0.3821\n","Epoch 29/30\n","16/16 [==============================] - 1s 88ms/step - loss: 2.8195e-07 - accuracy: 1.0000 - val_loss: 6.3632 - val_accuracy: 0.3902\n","Epoch 30/30\n","16/16 [==============================] - 1s 89ms/step - loss: 2.6018e-07 - accuracy: 1.0000 - val_loss: 6.3719 - val_accuracy: 0.3902\n","31/31 [==============================] - 0s 16ms/step - loss: 2.4145e-07 - accuracy: 1.0000\n","8/8 [==============================] - 0s 14ms/step - loss: 6.3719 - accuracy: 0.3902\n","5/5 [==============================] - 0s 12ms/step - loss: 6.3131 - accuracy: 0.3904\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R7RZWlUaV6kv"},"source":["## AlexNet"]},{"cell_type":"code","metadata":{"id":"3mVuV4gNXuZE","executionInfo":{"status":"ok","timestamp":1602717856923,"user_tz":420,"elapsed":422,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"9b33f34d-18b2-4a07-df6b-a0c675810b25","colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["# Ref: https://github.com/Keyird/DeepLearning-TensorFlow2/blob/master/4.%20AlexNet/AlexNet.py\n","Alex_layers=[\n","    # layer 1\n","    tf.keras.layers.Conv2D(48, kernel_size=11, strides=4, padding='same', activation='relu', input_shape=input_shape), \n","    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),  \n","    # layer 2\n","    tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu'),  \n","    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),  \n","    # layer 3\n","    tf.keras.layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu'), \n","    # layer 4\n","    tf.keras.layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    # layer 5\n","    tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n","    tf.keras.layers.Flatten(), \n","    # layer 6\n","    tf.keras.layers.Dense(1024, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    # layer 7\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    # layer 8\n","    tf.keras.layers.Dense(num_class)\n","]\n","\n","AlexNet=tf.keras.Sequential(Alex_layers)\n","AlexNet.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 56, 56, 48)        17472     \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 27, 27, 48)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 27, 27, 128)       153728    \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 13, 13, 192)       221376    \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 13, 13, 192)       331968    \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 13, 13, 128)       221312    \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              4719616   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               131200    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 5,797,059\n","Trainable params: 5,797,059\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jn2WDOI1YdyZ","executionInfo":{"status":"ok","timestamp":1602742069118,"user_tz":420,"elapsed":215635,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"d836bd23-1a8d-4ae7-dea6-ce9ba84418fc","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(AlexNet)\n","\n","train_performance['AlexNet'] = AlexNet.evaluate(train_x, train_y, verbose= 1)\n","val_performance['AlexNet'] = AlexNet.evaluate(val_x, val_y, verbose= 1)\n","performance['AlexNet'] = AlexNet.evaluate(test_X, test_y, verbose= 1)"],"execution_count":220,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0288 - accuracy: 0.1418 - val_loss: 1.1287 - val_accuracy: 0.1545\n","Epoch 2/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.2704 - accuracy: 0.1551 - val_loss: 1.5352 - val_accuracy: 0.1626\n","Epoch 3/30\n","16/16 [==============================] - 1s 42ms/step - loss: 0.9998 - accuracy: 0.1398 - val_loss: 1.1170 - val_accuracy: 0.1748\n","Epoch 4/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.0172 - accuracy: 0.1561 - val_loss: 1.0274 - val_accuracy: 0.1992\n","Epoch 5/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0775 - accuracy: 0.1490 - val_loss: 1.5887 - val_accuracy: 0.1789\n","Epoch 6/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.7334 - accuracy: 0.2041 - val_loss: 1.1982 - val_accuracy: 0.2114\n","Epoch 7/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.1290 - accuracy: 0.2153 - val_loss: 1.0442 - val_accuracy: 0.2114\n","Epoch 8/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0304 - accuracy: 0.1990 - val_loss: 1.0337 - val_accuracy: 0.1829\n","Epoch 9/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.0194 - accuracy: 0.1704 - val_loss: 1.0084 - val_accuracy: 0.1707\n","Epoch 10/30\n","16/16 [==============================] - 1s 42ms/step - loss: 0.9459 - accuracy: 0.1541 - val_loss: 1.2755 - val_accuracy: 0.1585\n","Epoch 11/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0321 - accuracy: 0.1439 - val_loss: 1.1483 - val_accuracy: 0.1748\n","Epoch 12/30\n","16/16 [==============================] - 1s 41ms/step - loss: 1.0000 - accuracy: 0.1357 - val_loss: 1.5355 - val_accuracy: 0.1789\n","Epoch 13/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.3133 - accuracy: 0.1837 - val_loss: 1.0577 - val_accuracy: 0.1911\n","Epoch 14/30\n","16/16 [==============================] - 1s 43ms/step - loss: 0.9909 - accuracy: 0.1673 - val_loss: 1.0785 - val_accuracy: 0.1829\n","Epoch 15/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0279 - accuracy: 0.1612 - val_loss: 0.9641 - val_accuracy: 0.1423\n","Epoch 16/30\n","16/16 [==============================] - 1s 42ms/step - loss: 0.9497 - accuracy: 0.1551 - val_loss: 1.0132 - val_accuracy: 0.1504\n","Epoch 17/30\n","16/16 [==============================] - 1s 41ms/step - loss: 0.9200 - accuracy: 0.1398 - val_loss: 1.0670 - val_accuracy: 0.1545\n","Epoch 18/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.2782 - accuracy: 0.1327 - val_loss: 1.6713 - val_accuracy: 0.1829\n","Epoch 19/30\n","16/16 [==============================] - 1s 41ms/step - loss: 4.7552 - accuracy: 0.2092 - val_loss: 2.0789 - val_accuracy: 0.2602\n","Epoch 20/30\n","16/16 [==============================] - 1s 44ms/step - loss: 1.3595 - accuracy: 0.3388 - val_loss: 1.0890 - val_accuracy: 0.4146\n","Epoch 21/30\n","16/16 [==============================] - 1s 44ms/step - loss: 1.1251 - accuracy: 0.4102 - val_loss: 1.0905 - val_accuracy: 0.4146\n","Epoch 22/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.0882 - accuracy: 0.4071 - val_loss: 1.0892 - val_accuracy: 0.4146\n","Epoch 23/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0954 - accuracy: 0.4214 - val_loss: 1.0846 - val_accuracy: 0.4146\n","Epoch 24/30\n","16/16 [==============================] - 1s 42ms/step - loss: 1.0852 - accuracy: 0.4245 - val_loss: 1.0842 - val_accuracy: 0.4146\n","Epoch 25/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0851 - accuracy: 0.4163 - val_loss: 1.0838 - val_accuracy: 0.4146\n","Epoch 26/30\n","16/16 [==============================] - 1s 44ms/step - loss: 1.0808 - accuracy: 0.4143 - val_loss: 1.0833 - val_accuracy: 0.4146\n","Epoch 27/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0910 - accuracy: 0.4245 - val_loss: 1.0844 - val_accuracy: 0.4146\n","Epoch 28/30\n","16/16 [==============================] - 1s 43ms/step - loss: 1.0674 - accuracy: 0.4245 - val_loss: 1.0830 - val_accuracy: 0.4146\n","Epoch 29/30\n","16/16 [==============================] - 1s 41ms/step - loss: 1.0837 - accuracy: 0.4204 - val_loss: 1.0832 - val_accuracy: 0.4146\n","Epoch 30/30\n","16/16 [==============================] - 1s 41ms/step - loss: 1.0854 - accuracy: 0.4255 - val_loss: 1.0824 - val_accuracy: 0.4146\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0772 - accuracy: 0.4316\n","8/8 [==============================] - 0s 10ms/step - loss: 1.0824 - accuracy: 0.4146\n","5/5 [==============================] - 0s 9ms/step - loss: 1.0686 - accuracy: 0.4589\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z_HXuHwc_vsP"},"source":["## VGG"]},{"cell_type":"markdown","metadata":{"id":"XRwn7WkCE89Q"},"source":["### VGG11"]},{"cell_type":"code","metadata":{"id":"wSdZflx_bnz-","executionInfo":{"status":"ok","timestamp":1602718193606,"user_tz":420,"elapsed":374,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"1e5678a0-1dc7-4f16-b4c1-50f38b20abcd","colab":{"base_uri":"https://localhost:8080/","height":799}},"source":["# Ref: https://github.com/Keyird/DeepLearning-TensorFlow2/blob/master/5.%20VGG11/VGG11.py\n","VGG11_layers=[\n","    # layer 1\n","    tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape = input_shape),\n","    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","    # layer 2\n","    tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","    # layer 3\n","    tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    # layer 4\n","    tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","    # layer 5\n","    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    # layer 6\n","    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","    # layer 7\n","    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    # layer 8\n","    tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n","    tf.keras.layers.Flatten(), \n","    # layer 9\n","    tf.keras.layers.Dense(1024, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    # layer 10\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    # layer 11\n","    tf.keras.layers.Dense(num_class, activation='softmax')\n","]\n","\n","VGG11=tf.keras.Sequential(VGG11_layers)\n","VGG11.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_13 (Conv2D)           (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1024)              25691136  \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 128)               131200    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 3)                 387       \n","=================================================================\n","Total params: 35,043,203\n","Trainable params: 35,043,203\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dg5qIVx8bn8A","executionInfo":{"status":"ok","timestamp":1602742046382,"user_tz":420,"elapsed":192918,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"3df30a8a-6148-4027-98e9-0fa338c08937","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(VGG11)\n","\n","train_performance['VGG11'] = VGG11.evaluate(train_x, train_y, verbose= 1)\n","val_performance['VGG11'] = VGG11.evaluate(val_x, val_y, verbose= 1)\n","performance['VGG11'] = VGG11.evaluate(test_X, test_y, verbose= 1)"],"execution_count":219,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 4s - loss: 0.0760 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1253s vs `on_train_batch_end` time: 0.2565s). Check your callbacks.\n","16/16 [==============================] - 6s 397ms/step - loss: 0.1085 - accuracy: 0.9633 - val_loss: 1.1917 - val_accuracy: 0.8008\n","Epoch 2/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 1.2009 - val_accuracy: 0.7683\n","Epoch 3/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 1.3640 - val_accuracy: 0.7724\n","Epoch 4/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0778 - accuracy: 0.9816 - val_loss: 1.5804 - val_accuracy: 0.7195\n","Epoch 5/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0628 - accuracy: 0.9827 - val_loss: 1.4561 - val_accuracy: 0.7154\n","Epoch 6/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.1000 - accuracy: 0.9755 - val_loss: 1.3159 - val_accuracy: 0.7317\n","Epoch 7/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 1.2564 - val_accuracy: 0.7358\n","Epoch 8/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 1.6064 - val_accuracy: 0.6992\n","Epoch 9/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.1004 - accuracy: 0.9765 - val_loss: 1.4293 - val_accuracy: 0.7114\n","Epoch 10/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 1.7592 - val_accuracy: 0.7480\n","Epoch 11/30\n","16/16 [==============================] - 6s 388ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 1.5299 - val_accuracy: 0.7398\n","Epoch 12/30\n","16/16 [==============================] - 6s 387ms/step - loss: 0.1235 - accuracy: 0.9663 - val_loss: 1.8042 - val_accuracy: 0.7033\n","Epoch 13/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.9067 - val_accuracy: 0.7642\n","Epoch 14/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 1.2510 - val_accuracy: 0.7398\n","Epoch 15/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0116 - accuracy: 0.9949 - val_loss: 1.1667 - val_accuracy: 0.7683\n","Epoch 16/30\n","16/16 [==============================] - 6s 387ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 1.4824 - val_accuracy: 0.7602\n","Epoch 17/30\n","16/16 [==============================] - 6s 387ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 1.4895 - val_accuracy: 0.7602\n","Epoch 18/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 1.5754 - val_accuracy: 0.7683\n","Epoch 19/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.1020 - accuracy: 0.9724 - val_loss: 1.6105 - val_accuracy: 0.7154\n","Epoch 20/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 1.4158 - val_accuracy: 0.7439\n","Epoch 21/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 1.3986 - val_accuracy: 0.7358\n","Epoch 22/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0437 - accuracy: 0.9898 - val_loss: 1.4904 - val_accuracy: 0.7236\n","Epoch 23/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.0555 - accuracy: 0.9796 - val_loss: 2.2430 - val_accuracy: 0.6585\n","Epoch 24/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.1050 - accuracy: 0.9776 - val_loss: 1.1562 - val_accuracy: 0.7439\n","Epoch 25/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.0839 - accuracy: 0.9745 - val_loss: 1.7354 - val_accuracy: 0.7276\n","Epoch 26/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 1.3091 - val_accuracy: 0.7480\n","Epoch 27/30\n","16/16 [==============================] - 6s 387ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 1.2858 - val_accuracy: 0.7480\n","Epoch 28/30\n","16/16 [==============================] - 6s 386ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 1.4026 - val_accuracy: 0.7520\n","Epoch 29/30\n","16/16 [==============================] - 6s 385ms/step - loss: 0.0560 - accuracy: 0.9888 - val_loss: 1.5360 - val_accuracy: 0.6707\n","Epoch 30/30\n","16/16 [==============================] - 6s 384ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 1.4603 - val_accuracy: 0.7398\n","31/31 [==============================] - 2s 58ms/step - loss: 7.6826e-04 - accuracy: 1.0000\n","8/8 [==============================] - 0s 53ms/step - loss: 1.4603 - accuracy: 0.7398\n","5/5 [==============================] - 0s 47ms/step - loss: 3.5334 - accuracy: 0.5685\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZzvKzJu8zkP"},"source":["### VGG16"]},{"cell_type":"code","metadata":{"id":"LG8C7sHa83po","executionInfo":{"status":"ok","timestamp":1602743548002,"user_tz":420,"elapsed":433,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"16136d8e-4f5b-42cd-cac1-e375e443eba6","colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["# Ref: https://keras.io/api/applications/vgg/\n","VGG16 = tf.keras.applications.VGG16(\n","    include_top=True,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=input_shape,\n","    pooling= max,\n","    classes= num_class,\n","    classifier_activation=\"softmax\",\n",")\n","\n","VGG16.summary()"],"execution_count":228,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_31 (InputLayer)        [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 3)                 12291     \n","=================================================================\n","Total params: 134,272,835\n","Trainable params: 134,272,835\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifvLb3OZ8zO8","executionInfo":{"status":"ok","timestamp":1602743961740,"user_tz":420,"elapsed":408513,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"54febb5e-a583-483e-b0df-157a0e91e77e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(VGG16)\n","\n","train_performance['VGG16'] = VGG16.evaluate(train_x, train_y, verbose= 1)\n","val_performance['VGG16'] = VGG16.evaluate(val_x, val_y, verbose= 1)\n","performance['VGG16'] = VGG16.evaluate(test_X, test_y, verbose= 1)"],"execution_count":229,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 6s - loss: 8267.9902 - accuracy: 0.4922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2478s vs `on_train_batch_end` time: 0.5455s). Check your callbacks.\n","16/16 [==============================] - 14s 898ms/step - loss: 1080.9412 - accuracy: 0.3653 - val_loss: 1.1003 - val_accuracy: 0.3293\n","Epoch 2/30\n","16/16 [==============================] - 13s 806ms/step - loss: 1.1446 - accuracy: 0.4000 - val_loss: 1.0875 - val_accuracy: 0.4187\n","Epoch 3/30\n","16/16 [==============================] - 13s 819ms/step - loss: 1.0858 - accuracy: 0.4306 - val_loss: 1.0825 - val_accuracy: 0.4146\n","Epoch 4/30\n","16/16 [==============================] - 13s 827ms/step - loss: 1.0786 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n","Epoch 5/30\n","16/16 [==============================] - 13s 816ms/step - loss: 1.0757 - accuracy: 0.4316 - val_loss: 1.0907 - val_accuracy: 0.4146\n","Epoch 6/30\n","16/16 [==============================] - 13s 805ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0808 - val_accuracy: 0.4146\n","Epoch 7/30\n","16/16 [==============================] - 13s 805ms/step - loss: 1.0847 - accuracy: 0.4316 - val_loss: 1.0815 - val_accuracy: 0.4146\n","Epoch 8/30\n","16/16 [==============================] - 13s 807ms/step - loss: 1.0775 - accuracy: 0.4316 - val_loss: 1.0812 - val_accuracy: 0.4146\n","Epoch 9/30\n","16/16 [==============================] - 13s 810ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0811 - val_accuracy: 0.4146\n","Epoch 10/30\n","16/16 [==============================] - 13s 814ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0809 - val_accuracy: 0.4146\n","Epoch 11/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0774 - accuracy: 0.4316 - val_loss: 1.0805 - val_accuracy: 0.4146\n","Epoch 12/30\n","16/16 [==============================] - 13s 813ms/step - loss: 1.0752 - accuracy: 0.4316 - val_loss: 1.0791 - val_accuracy: 0.4146\n","Epoch 13/30\n","16/16 [==============================] - 13s 807ms/step - loss: 1.0714 - accuracy: 0.4367 - val_loss: 1.0761 - val_accuracy: 0.4146\n","Epoch 14/30\n","16/16 [==============================] - 13s 812ms/step - loss: 1.0772 - accuracy: 0.4316 - val_loss: 1.0828 - val_accuracy: 0.4146\n","Epoch 15/30\n","16/16 [==============================] - 13s 806ms/step - loss: 1.0760 - accuracy: 0.4296 - val_loss: 1.0797 - val_accuracy: 0.4146\n","Epoch 16/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0766 - accuracy: 0.4316 - val_loss: 1.0828 - val_accuracy: 0.4146\n","Epoch 17/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0756 - accuracy: 0.4316 - val_loss: 1.0952 - val_accuracy: 0.4146\n","Epoch 18/30\n","16/16 [==============================] - 13s 807ms/step - loss: 1.0789 - accuracy: 0.4224 - val_loss: 1.0807 - val_accuracy: 0.4146\n","Epoch 19/30\n","16/16 [==============================] - 13s 808ms/step - loss: 1.0715 - accuracy: 0.4286 - val_loss: 1.0749 - val_accuracy: 0.4390\n","Epoch 20/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0681 - accuracy: 0.4255 - val_loss: 1.0813 - val_accuracy: 0.4146\n","Epoch 21/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0745 - accuracy: 0.4316 - val_loss: 1.0747 - val_accuracy: 0.4106\n","Epoch 22/30\n","16/16 [==============================] - 13s 810ms/step - loss: 1.0657 - accuracy: 0.4418 - val_loss: 1.0471 - val_accuracy: 0.4309\n","Epoch 23/30\n","16/16 [==============================] - 13s 810ms/step - loss: 1.0386 - accuracy: 0.4735 - val_loss: 1.0204 - val_accuracy: 0.4756\n","Epoch 24/30\n","16/16 [==============================] - 13s 812ms/step - loss: 1.0170 - accuracy: 0.5051 - val_loss: 0.9862 - val_accuracy: 0.4593\n","Epoch 25/30\n","16/16 [==============================] - 13s 808ms/step - loss: 1.0881 - accuracy: 0.4837 - val_loss: 1.0816 - val_accuracy: 0.4228\n","Epoch 26/30\n","16/16 [==============================] - 13s 809ms/step - loss: 1.0805 - accuracy: 0.4500 - val_loss: 1.0797 - val_accuracy: 0.4187\n","Epoch 27/30\n","16/16 [==============================] - 13s 807ms/step - loss: 1.0503 - accuracy: 0.4520 - val_loss: 1.1973 - val_accuracy: 0.2927\n","Epoch 28/30\n","16/16 [==============================] - 13s 811ms/step - loss: 1.1199 - accuracy: 0.3908 - val_loss: 1.0690 - val_accuracy: 0.4106\n","Epoch 29/30\n","16/16 [==============================] - 13s 812ms/step - loss: 1.1172 - accuracy: 0.4286 - val_loss: 1.0842 - val_accuracy: 0.4146\n","Epoch 30/30\n","16/16 [==============================] - 13s 811ms/step - loss: 1.0899 - accuracy: 0.4235 - val_loss: 1.0844 - val_accuracy: 0.4146\n","31/31 [==============================] - 4s 121ms/step - loss: 1.0770 - accuracy: 0.4316\n","8/8 [==============================] - 1s 159ms/step - loss: 1.0844 - accuracy: 0.4146\n","5/5 [==============================] - 1s 168ms/step - loss: 1.0667 - accuracy: 0.4589\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f_pPK0lq9fNE"},"source":["### VGG19"]},{"cell_type":"code","metadata":{"id":"ykwB7ckD9hBG","executionInfo":{"status":"ok","timestamp":1602743962569,"user_tz":420,"elapsed":417,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"46330e0f-4154-465e-d0e6-ea29b11d1a02","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Ref: https://keras.io/api/applications/vgg/\n","VGG19 = tf.keras.applications.VGG19(\n","    include_top=True,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=input_shape,\n","    pooling= max,\n","    classes= num_class,\n","    classifier_activation=\"softmax\",\n",")\n","\n","VGG19.summary()"],"execution_count":230,"outputs":[{"output_type":"stream","text":["Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_32 (InputLayer)        [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 3)                 12291     \n","=================================================================\n","Total params: 139,582,531\n","Trainable params: 139,582,531\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AuPBZ2Oo9ttW","executionInfo":{"status":"ok","timestamp":1602744434841,"user_tz":420,"elapsed":472685,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"0f83fe55-7be2-4438-fdb5-53c58c7edce2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(VGG19)\n","\n","train_performance['VGG19'] = VGG19.evaluate(train_x, train_y, verbose= 1)\n","val_performance['VGG19'] = VGG19.evaluate(val_x, val_y, verbose= 1)\n","performance['VGG19'] = VGG19.evaluate(test_X, test_y, verbose= 1)"],"execution_count":231,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 11s - loss: 54836.3984 - accuracy: 0.3516WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3198s vs `on_train_batch_end` time: 0.6607s). Check your callbacks.\n","16/16 [==============================] - 16s 984ms/step - loss: 7163.2656 - accuracy: 0.3602 - val_loss: 1.1120 - val_accuracy: 0.3252\n","Epoch 2/30\n","16/16 [==============================] - 15s 950ms/step - loss: 1.1383 - accuracy: 0.3908 - val_loss: 1.0788 - val_accuracy: 0.3496\n","Epoch 3/30\n","16/16 [==============================] - 15s 952ms/step - loss: 1.0814 - accuracy: 0.4255 - val_loss: 1.0767 - val_accuracy: 0.4146\n","Epoch 4/30\n","16/16 [==============================] - 16s 977ms/step - loss: 1.0884 - accuracy: 0.4316 - val_loss: 1.0889 - val_accuracy: 0.4146\n","Epoch 5/30\n","16/16 [==============================] - 15s 950ms/step - loss: 1.0898 - accuracy: 0.4316 - val_loss: 1.0864 - val_accuracy: 0.4146\n","Epoch 6/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.0820 - accuracy: 0.4316 - val_loss: 1.0816 - val_accuracy: 0.4146\n","Epoch 7/30\n","16/16 [==============================] - 15s 951ms/step - loss: 1.0770 - accuracy: 0.4316 - val_loss: 1.0936 - val_accuracy: 0.4146\n","Epoch 8/30\n","16/16 [==============================] - 15s 948ms/step - loss: 1.0715 - accuracy: 0.4316 - val_loss: 1.0756 - val_accuracy: 0.4146\n","Epoch 9/30\n","16/16 [==============================] - 15s 954ms/step - loss: 1.0772 - accuracy: 0.4316 - val_loss: 1.0763 - val_accuracy: 0.4146\n","Epoch 10/30\n","16/16 [==============================] - 15s 948ms/step - loss: 1.0767 - accuracy: 0.4316 - val_loss: 1.0723 - val_accuracy: 0.4146\n","Epoch 11/30\n","16/16 [==============================] - 15s 944ms/step - loss: 1.0786 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n","Epoch 12/30\n","16/16 [==============================] - 15s 949ms/step - loss: 1.0782 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n","Epoch 13/30\n","16/16 [==============================] - 15s 953ms/step - loss: 1.0768 - accuracy: 0.4316 - val_loss: 1.0817 - val_accuracy: 0.4146\n","Epoch 14/30\n","16/16 [==============================] - 15s 951ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0809 - val_accuracy: 0.4146\n","Epoch 15/30\n","16/16 [==============================] - 15s 950ms/step - loss: 1.0760 - accuracy: 0.4316 - val_loss: 1.0781 - val_accuracy: 0.4146\n","Epoch 16/30\n","16/16 [==============================] - 15s 948ms/step - loss: 1.0774 - accuracy: 0.4276 - val_loss: 1.0809 - val_accuracy: 0.4146\n","Epoch 17/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.0784 - accuracy: 0.4276 - val_loss: 1.0829 - val_accuracy: 0.4146\n","Epoch 18/30\n","16/16 [==============================] - 15s 946ms/step - loss: 1.0795 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n","Epoch 19/30\n","16/16 [==============================] - 15s 941ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n","Epoch 20/30\n","16/16 [==============================] - 15s 943ms/step - loss: 1.0763 - accuracy: 0.4316 - val_loss: 1.0816 - val_accuracy: 0.4146\n","Epoch 21/30\n","16/16 [==============================] - 15s 946ms/step - loss: 1.0777 - accuracy: 0.4316 - val_loss: 1.0813 - val_accuracy: 0.4146\n","Epoch 22/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.0768 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n","Epoch 23/30\n","16/16 [==============================] - 15s 948ms/step - loss: 1.0769 - accuracy: 0.4316 - val_loss: 1.0814 - val_accuracy: 0.4146\n","Epoch 24/30\n","16/16 [==============================] - 15s 945ms/step - loss: 1.0766 - accuracy: 0.4316 - val_loss: 1.0807 - val_accuracy: 0.4146\n","Epoch 25/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.0798 - accuracy: 0.4316 - val_loss: 1.0806 - val_accuracy: 0.4146\n","Epoch 26/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.1127 - accuracy: 0.4316 - val_loss: 1.0830 - val_accuracy: 0.4146\n","Epoch 27/30\n","16/16 [==============================] - 15s 948ms/step - loss: 1.0797 - accuracy: 0.4316 - val_loss: 1.0823 - val_accuracy: 0.4146\n","Epoch 28/30\n","16/16 [==============================] - 15s 946ms/step - loss: 1.0791 - accuracy: 0.4306 - val_loss: 1.0819 - val_accuracy: 0.4146\n","Epoch 29/30\n","16/16 [==============================] - 15s 946ms/step - loss: 1.0767 - accuracy: 0.4316 - val_loss: 1.0825 - val_accuracy: 0.4146\n","Epoch 30/30\n","16/16 [==============================] - 15s 947ms/step - loss: 1.0774 - accuracy: 0.4316 - val_loss: 1.0811 - val_accuracy: 0.4146\n","31/31 [==============================] - 4s 144ms/step - loss: 1.0762 - accuracy: 0.4316\n","8/8 [==============================] - 1s 129ms/step - loss: 1.0811 - accuracy: 0.4146\n","5/5 [==============================] - 1s 110ms/step - loss: 1.0680 - accuracy: 0.4589\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W9my4tlYcwUN"},"source":["## GoogleNet"]},{"cell_type":"code","metadata":{"id":"hbeaQO6fleFx","executionInfo":{"status":"ok","timestamp":1602741588961,"user_tz":420,"elapsed":1387,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"4f477a70-656b-4dcd-9f83-567624b0056b","colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["# Ref: https://github.com/guaiguaibao/GoogLeNet_Tensorflow2.0/blob/master/tensorflow2.0/GoogLeNet/model.py\n","def GoogLeNet(im_height=224, im_width=224, class_num=num_class, aux_logits=False):\n","    input_image = layers.Input(shape= input_shape, dtype=\"float32\")\n","    # (None, 224, 224, 3)\n","    x = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"SAME\", activation=\"relu\", name=\"conv2d_1\")(input_image)\n","    # (None, 112, 112, 64)\n","    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_1\")(x)\n","    # (None, 56, 56, 64)\n","    x = layers.Conv2D(64, kernel_size=1, activation=\"relu\", name=\"conv2d_2\")(x)\n","    # (None, 56, 56, 64)\n","    x = layers.Conv2D(192, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"conv2d_3\")(x)\n","    # (None, 56, 56, 192)\n","    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_2\")(x)\n","\n","    # (None, 28, 28, 192)\n","    x = Inception(64, 96, 128, 16, 32, 32, name=\"inception_3a\")(x)\n","    # (None, 28, 28, 256)\n","    x = Inception(128, 128, 192, 32, 96, 64, name=\"inception_3b\")(x)\n","\n","    # (None, 28, 28, 480)\n","    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_3\")(x)\n","    # (None, 14, 14, 480)\n","    x = Inception(192, 96, 208, 16, 48, 64, name=\"inception_4a\")(x)\n","    if aux_logits:\n","        aux1 = InceptionAux(class_num, name=\"aux_1\")(x)\n","\n","    # (None, 14, 14, 512)\n","    x = Inception(160, 112, 224, 24, 64, 64, name=\"inception_4b\")(x)\n","    # (None, 14, 14, 512)\n","    x = Inception(128, 128, 256, 24, 64, 64, name=\"inception_4c\")(x)\n","    # (None, 14, 14, 512)\n","    x = Inception(112, 144, 288, 32, 64, 64, name=\"inception_4d\")(x)\n","    if aux_logits:\n","        aux2 = InceptionAux(class_num, name=\"aux_2\")(x)\n","\n","    # (None, 14, 14, 528)\n","    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_4e\")(x)\n","    # (None, 14, 14, 532)\n","    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_4\")(x)\n","\n","    # (None, 7, 7, 832)\n","    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_5a\")(x)\n","    # (None, 7, 7, 832)\n","    x = Inception(384, 192, 384, 48, 128, 128, name=\"inception_5b\")(x)\n","    # (None, 7, 7, 1024)\n","    x = layers.AvgPool2D(pool_size=7, strides=1, name=\"avgpool_1\")(x)\n","\n","    # (None, 1, 1, 1024)\n","    x = layers.Flatten(name=\"output_flatten\")(x)\n","    # (None, 1024)\n","    x = layers.Dropout(rate=0.4, name=\"output_dropout\")(x)\n","    x = layers.Dense(class_num, name=\"output_dense\")(x)\n","    # (None, class_num)\n","    aux3 = layers.Softmax(name=\"aux_3\")(x)\n","\n","    if aux_logits:\n","        model = models.Model(inputs=input_image, outputs=[aux1, aux2, aux3])\n","    else:\n","        model = models.Model(inputs=input_image, outputs=aux3)\n","    return model\n","\n","\n","# Inception\n","class Inception(layers.Layer):\n","    def __init__(self, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, **kwargs):\n","       \n","        super(Inception, self).__init__(**kwargs)\n","        self.branch1 = layers.Conv2D(ch1x1, kernel_size=1, activation=\"relu\")\n","\n","        self.branch2 = Sequential([\n","            layers.Conv2D(ch3x3red, kernel_size=1, activation=\"relu\"),\n","            layers.Conv2D(ch3x3, kernel_size=3, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n","\n","        self.branch3 = Sequential([\n","            layers.Conv2D(ch5x5red, kernel_size=1, activation=\"relu\"),\n","            layers.Conv2D(ch5x5, kernel_size=5, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n","\n","        self.branch4 = Sequential([\n","            layers.MaxPool2D(pool_size=3, strides=1, padding=\"SAME\"),  # caution: default strides==pool_size\n","            layers.Conv2D(pool_proj, kernel_size=1, activation=\"relu\")])                  # output_size= input_size\n","\n","    def call(self, inputs, **kwargs):\n","        branch1 = self.branch1(inputs)\n","        branch2 = self.branch2(inputs)\n","        branch3 = self.branch3(inputs)\n","        branch4 = self.branch4(inputs)\n","        outputs = layers.concatenate([branch1, branch2, branch3, branch4])\n","        return outputs\n","\n","\n","class InceptionAux(layers.Layer):\n","    def __init__(self, num_classes, **kwargs):\n","        super(InceptionAux, self).__init__(**kwargs)\n","        self.averagePool = layers.AvgPool2D(pool_size=5, strides=3)\n","        self.conv = layers.Conv2D(128, kernel_size=1, activation=\"relu\")\n","\n","        self.fc1 = layers.Dense(1024, activation=\"relu\")\n","        self.fc2 = layers.Dense(num_classes)\n","        self.softmax = layers.Softmax()\n","\n","    def call(self, inputs, **kwargs):\n","        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n","        x = self.averagePool(inputs)\n","        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n","        x = self.conv(x)\n","        # N x 128 x 4 x 4\n","        x = layers.Flatten()(x)\n","        x = layers.Dropout(rate=0.5)(x)  \n","        # N x 2048\n","        x = self.fc1(x)\n","        x = layers.Dropout(rate=0.5)(x)\n","        # N x 1024\n","        x = self.fc2(x)\n","        # N x num_classes\n","        x = self.softmax(x)\n","\n","        return x\n","\n","GoogleNet_model = GoogLeNet(class_num = num_class)\n","GoogleNet_model.summary()"],"execution_count":216,"outputs":[{"output_type":"stream","text":["Model: \"functional_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_30 (InputLayer)        [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 112, 112, 64)      9472      \n","_________________________________________________________________\n","maxpool_1 (MaxPooling2D)     (None, 56, 56, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 56, 56, 64)        4160      \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 56, 56, 192)       110784    \n","_________________________________________________________________\n","maxpool_2 (MaxPooling2D)     (None, 28, 28, 192)       0         \n","_________________________________________________________________\n","inception_3a (Inception)     (None, 28, 28, 256)       163696    \n","_________________________________________________________________\n","inception_3b (Inception)     (None, 28, 28, 480)       388736    \n","_________________________________________________________________\n","maxpool_3 (MaxPooling2D)     (None, 14, 14, 480)       0         \n","_________________________________________________________________\n","inception_4a (Inception)     (None, 14, 14, 512)       376176    \n","_________________________________________________________________\n","inception_4b (Inception)     (None, 14, 14, 512)       449160    \n","_________________________________________________________________\n","inception_4c (Inception)     (None, 14, 14, 512)       510104    \n","_________________________________________________________________\n","inception_4d (Inception)     (None, 14, 14, 528)       605376    \n","_________________________________________________________________\n","inception_4e (Inception)     (None, 14, 14, 832)       868352    \n","_________________________________________________________________\n","maxpool_4 (MaxPooling2D)     (None, 7, 7, 832)         0         \n","_________________________________________________________________\n","inception_5a (Inception)     (None, 7, 7, 832)         1043456   \n","_________________________________________________________________\n","inception_5b (Inception)     (None, 7, 7, 1024)        1444080   \n","_________________________________________________________________\n","avgpool_1 (AveragePooling2D) (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","output_flatten (Flatten)     (None, 1024)              0         \n","_________________________________________________________________\n","output_dropout (Dropout)     (None, 1024)              0         \n","_________________________________________________________________\n","output_dense (Dense)         (None, 3)                 3075      \n","_________________________________________________________________\n","aux_3 (Softmax)              (None, 3)                 0         \n","=================================================================\n","Total params: 5,976,627\n","Trainable params: 5,976,627\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gMyrz53JhBOy","executionInfo":{"status":"ok","timestamp":1602742244998,"user_tz":420,"elapsed":112411,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"5d1de344-c872-4261-d61d-33c79c764a1c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(GoogleNet_model)\n","\n","train_performance['GoogleNet_model'] = GoogleNet_model.evaluate(train_x, train_y, verbose= 1)\n","val_performance['GoogleNet_model'] = GoogleNet_model.evaluate(val_x, val_y, verbose= 1)\n","performance['GoogleNet_model'] = GoogleNet_model.evaluate(test_X, test_y, verbose= 1)"],"execution_count":224,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 2s - loss: 1.5497 - accuracy: 0.5859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0808s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n","16/16 [==============================] - 4s 249ms/step - loss: 1.0514 - accuracy: 0.5796 - val_loss: 0.8439 - val_accuracy: 0.6382\n","Epoch 2/30\n","16/16 [==============================] - 3s 210ms/step - loss: 0.7843 - accuracy: 0.6347 - val_loss: 0.8312 - val_accuracy: 0.6260\n","Epoch 3/30\n","16/16 [==============================] - 3s 212ms/step - loss: 0.7243 - accuracy: 0.6520 - val_loss: 0.7814 - val_accuracy: 0.6545\n","Epoch 4/30\n","16/16 [==============================] - 3s 213ms/step - loss: 0.6915 - accuracy: 0.6816 - val_loss: 0.7177 - val_accuracy: 0.6667\n","Epoch 5/30\n","16/16 [==============================] - 3s 215ms/step - loss: 0.6381 - accuracy: 0.7245 - val_loss: 0.7233 - val_accuracy: 0.6748\n","Epoch 6/30\n","16/16 [==============================] - 3s 216ms/step - loss: 0.6188 - accuracy: 0.7163 - val_loss: 0.6997 - val_accuracy: 0.7033\n","Epoch 7/30\n","16/16 [==============================] - 3s 217ms/step - loss: 0.5923 - accuracy: 0.7439 - val_loss: 0.8003 - val_accuracy: 0.6748\n","Epoch 8/30\n","16/16 [==============================] - 3s 217ms/step - loss: 0.5688 - accuracy: 0.7480 - val_loss: 0.7299 - val_accuracy: 0.6423\n","Epoch 9/30\n","16/16 [==============================] - 4s 219ms/step - loss: 0.5453 - accuracy: 0.7602 - val_loss: 0.7147 - val_accuracy: 0.6992\n","Epoch 10/30\n","16/16 [==============================] - 3s 218ms/step - loss: 0.5187 - accuracy: 0.7939 - val_loss: 0.7126 - val_accuracy: 0.7073\n","Epoch 11/30\n","16/16 [==============================] - 4s 220ms/step - loss: 0.4845 - accuracy: 0.8041 - val_loss: 0.8132 - val_accuracy: 0.6748\n","Epoch 12/30\n","16/16 [==============================] - 4s 220ms/step - loss: 0.5203 - accuracy: 0.7592 - val_loss: 0.7696 - val_accuracy: 0.6748\n","Epoch 13/30\n","16/16 [==============================] - 3s 218ms/step - loss: 0.4278 - accuracy: 0.8255 - val_loss: 0.9036 - val_accuracy: 0.6748\n","Epoch 14/30\n","16/16 [==============================] - 3s 216ms/step - loss: 0.4177 - accuracy: 0.8204 - val_loss: 0.8647 - val_accuracy: 0.6626\n","Epoch 15/30\n","16/16 [==============================] - 3s 217ms/step - loss: 0.3881 - accuracy: 0.8541 - val_loss: 1.2226 - val_accuracy: 0.6098\n","Epoch 16/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.4735 - accuracy: 0.7898 - val_loss: 0.8824 - val_accuracy: 0.6789\n","Epoch 17/30\n","16/16 [==============================] - 3s 217ms/step - loss: 0.3428 - accuracy: 0.8602 - val_loss: 1.0364 - val_accuracy: 0.6789\n","Epoch 18/30\n","16/16 [==============================] - 3s 215ms/step - loss: 0.3157 - accuracy: 0.8837 - val_loss: 0.9708 - val_accuracy: 0.6260\n","Epoch 19/30\n","16/16 [==============================] - 3s 213ms/step - loss: 0.2429 - accuracy: 0.9082 - val_loss: 1.2393 - val_accuracy: 0.6545\n","Epoch 20/30\n","16/16 [==============================] - 3s 213ms/step - loss: 0.2970 - accuracy: 0.8939 - val_loss: 1.0393 - val_accuracy: 0.6260\n","Epoch 21/30\n","16/16 [==============================] - 3s 215ms/step - loss: 0.2841 - accuracy: 0.9031 - val_loss: 1.0627 - val_accuracy: 0.6789\n","Epoch 22/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.2092 - accuracy: 0.9296 - val_loss: 1.3588 - val_accuracy: 0.6301\n","Epoch 23/30\n","16/16 [==============================] - 3s 213ms/step - loss: 0.2031 - accuracy: 0.9276 - val_loss: 1.0562 - val_accuracy: 0.6951\n","Epoch 24/30\n","16/16 [==============================] - 3s 216ms/step - loss: 0.1790 - accuracy: 0.9367 - val_loss: 2.5875 - val_accuracy: 0.6138\n","Epoch 25/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.6290 - accuracy: 0.7612 - val_loss: 0.7395 - val_accuracy: 0.7033\n","Epoch 26/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.3342 - accuracy: 0.8878 - val_loss: 0.9329 - val_accuracy: 0.6748\n","Epoch 27/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.2673 - accuracy: 0.9000 - val_loss: 1.3811 - val_accuracy: 0.6341\n","Epoch 28/30\n","16/16 [==============================] - 3s 214ms/step - loss: 0.3528 - accuracy: 0.8745 - val_loss: 1.0357 - val_accuracy: 0.6585\n","Epoch 29/30\n","16/16 [==============================] - 3s 215ms/step - loss: 0.1499 - accuracy: 0.9561 - val_loss: 1.3027 - val_accuracy: 0.6382\n","Epoch 30/30\n","16/16 [==============================] - 3s 215ms/step - loss: 0.1171 - accuracy: 0.9663 - val_loss: 1.7198 - val_accuracy: 0.6463\n","31/31 [==============================] - 1s 37ms/step - loss: 0.1143 - accuracy: 0.9602\n","8/8 [==============================] - 0s 32ms/step - loss: 1.7198 - accuracy: 0.6463\n","5/5 [==============================] - 0s 29ms/step - loss: 1.6232 - accuracy: 0.6027\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9ERC8wjBrfV8"},"source":["## ResNet"]},{"cell_type":"code","metadata":{"id":"u0KJd6iVrebS"},"source":["# Resnet: https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/3-Neural_Network_Architecture/resnet.py\n","# Doesn't work for dimension reason\n","# class BasicBlock(tf.keras.Model):\n","#     expansion = 1\n","\n","#     def __init__(self, in_channels, out_channels, strides=1):\n","#         super(BasicBlock, self).__init__()\n","#         self.conv1 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=strides,\n","#                                             padding=\"same\", use_bias=False)\n","#         self.bn1 = tf.keras.layers.BatchNormalization()\n","\n","#         self.conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=1,\n","#                                             padding=\"same\", use_bias=False)\n","#         self.bn2 = tf.keras.layers.BatchNormalization()\n","\n","#         \"\"\"\n","#         Adds a shortcut between input and residual block and merges them with \"sum\"\n","#         \"\"\"\n","#         if strides != 1 or in_channels != self.expansion * out_channels:\n","#             self.shortcut = tf.keras.Sequential([\n","#                     tf.keras.layers.Conv2D(self.expansion*out_channels, kernel_size=1,\n","#                                            strides=strides, use_bias=False),\n","#                     tf.keras.layers.BatchNormalization()]\n","#                     )\n","#         else:\n","#             self.shortcut = lambda x,_: x\n","\n","#     def call(self, x, training=False):\n","#         # if training: print(\"=> training network ... \")\n","#         out = tf.nn.relu(self.bn1(self.conv1(x), training=training))\n","#         out = self.bn2(self.conv2(out), training=training)\n","#         out += self.shortcut(x, training)\n","#         return tf.nn.relu(out)\n","\n","\n","# class Bottleneck(tf.keras.Model):\n","#     expansion = 4\n","\n","#     def __init__(self, in_channels, out_channels, strides=1):\n","#         super(Bottleneck, self).__init__()\n","\n","#         self.conv1 = tf.keras.layers.Conv2D(out_channels, 1, 1, use_bias=False)\n","#         self.bn1 = tf.keras.layers.BatchNormalization()\n","#         self.conv2 = tf.keras.layers.Conv2D(out_channels, 3, strides, padding=\"same\", use_bias=False)\n","#         self.bn2 = tf.keras.layers.BatchNormalization()\n","#         self.conv3 = tf.keras.layers.Conv2D(out_channels*self.expansion, 1, 1, use_bias=False)\n","#         self.bn3 = tf.keras.layers.BatchNormalization()\n","\n","#         if strides != 1 or in_channels != self.expansion * out_channels:\n","#             self.shortcut = tf.keras.Sequential([\n","#                     tf.keras.layers.Conv2D(self.expansion*out_channels, kernel_size=1,\n","#                                            strides=strides, use_bias=False),\n","#                     tf.keras.layers.BatchNormalization()]\n","#                     )\n","#         else:\n","#             self.shortcut = lambda x,_: x\n","\n","#     def call(self, x, training=False):\n","#         out = tf.nn.relu(self.bn1(self.conv1(x), training))\n","#         out = tf.nn.relu(self.bn2(self.conv2(out), training))\n","#         out = self.bn3(self.conv3(out), training)\n","#         out += self.shortcut(x, training)\n","#         return tf.nn.relu(out)\n","\n","\n","# class ResNet(tf.keras.Model):\n","#     def __init__(self, block, num_blocks, num_classes= num_class):\n","#         super(ResNet, self).__init__()\n","#         self.in_channels = 64\n","\n","#         self.conv1 = tf.keras.layers.Conv2D(64, 3, 1, padding=\"same\", use_bias=False)\n","#         self.bn1 = tf.keras.layers.BatchNormalization()\n","\n","#         self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n","#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","\n","#         self.avg_pool2d = tf.keras.layers.AveragePooling2D(4)\n","#         self.linear = tf.keras.layers.Dense(units=num_classes, activation=\"softmax\")\n","\n","#     def _make_layer(self, block, out_channels, num_blocks, stride):\n","#         strides = [stride] + [1] * (num_blocks - 1)\n","#         layers = []\n","#         for stride in strides:\n","#             layers.append(block(self.in_channels, out_channels, stride))\n","#             self.in_channels = out_channels * block.expansion\n","#         return tf.keras.Sequential(layers)\n","\n","#     def call(self, x, training=False):\n","#         out = tf.nn.relu(self.bn1(self.conv1(x), training))\n","#         out = self.layer1(out, training=training)\n","#         out = self.layer2(out, training=training)\n","#         out = self.layer3(out, training=training)\n","#         out = self.layer4(out, training=training)\n","\n","#         # For classification\n","#         out = self.avg_pool2d(out)\n","#         out = tf.reshape(out, (out.shape[0], -1))\n","#         out = self.linear(out)\n","#         return out\n","\n","# def ResNet18():\n","#     return ResNet(BasicBlock, [2,2,2,2])\n","\n","# def ResNet34():\n","#     return ResNet(BasicBlock, [3,4,6,3])\n","\n","# def ResNet50():\n","#     return ResNet(Bottleneck, [3,4,14,3])\n","\n","# def ResNet101():\n","#     return ResNet(Bottleneck, [3,4,23,3])\n","\n","# def ResNet152():\n","#     return ResNet(Bottleneck, [3,8,36,3])\n","\n","# ResNet_model = ResNet152()\n","# ResNet_model.build(input_shape= (64, train_x.shape[1], train_x.shape[2], train_x.shape[3]))\n","# ResNet_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhKjK7rDFEzn"},"source":["### Resnet 50"]},{"cell_type":"code","metadata":{"id":"YfLi6yh2-4Hs"},"source":["# Ref: https://keras.io/api/applications/resnet/\n","ResNet50 = tf.keras.applications.ResNet50(\n","    include_top=True,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=input_shape,\n","    pooling= max,\n","    classes= num_class,\n","    classifier_activation=\"softmax\",\n",")\n","\n","ResNet50.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5i4zF7ZA-5Uf","executionInfo":{"status":"ok","timestamp":1602744773333,"user_tz":420,"elapsed":336623,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"bb50cda7-d340-44c5-c7fd-3bcee1c1309e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = compile_and_fit(ResNet50)\n","\n","train_performance['ResNet50'] = ResNet50.evaluate(train_x, train_y, verbose= 1)\n","val_performance['ResNet50'] = ResNet50.evaluate(val_x, val_y, verbose= 1)\n","performance['ResNet50'] = ResNet50.evaluate(test_X, test_y, verbose= 1)"],"execution_count":233,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 2/16 [==>...........................] - ETA: 4s - loss: 3.4131 - accuracy: 0.3906WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2384s vs `on_train_batch_end` time: 0.3888s). Check your callbacks.\n","16/16 [==============================] - 12s 747ms/step - loss: 2.2555 - accuracy: 0.4347 - val_loss: 4300.2173 - val_accuracy: 0.4146\n","Epoch 2/30\n","16/16 [==============================] - 11s 657ms/step - loss: 1.0825 - accuracy: 0.5316 - val_loss: 943.2739 - val_accuracy: 0.3902\n","Epoch 3/30\n","16/16 [==============================] - 11s 673ms/step - loss: 0.8258 - accuracy: 0.6071 - val_loss: 113.3269 - val_accuracy: 0.4309\n","Epoch 4/30\n","16/16 [==============================] - 11s 663ms/step - loss: 0.7658 - accuracy: 0.6541 - val_loss: 4.9887 - val_accuracy: 0.4553\n","Epoch 5/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.7563 - accuracy: 0.6480 - val_loss: 1.1064 - val_accuracy: 0.4959\n","Epoch 6/30\n","16/16 [==============================] - 10s 650ms/step - loss: 0.6313 - accuracy: 0.7347 - val_loss: 1.0812 - val_accuracy: 0.5081\n","Epoch 7/30\n","16/16 [==============================] - 10s 645ms/step - loss: 0.5495 - accuracy: 0.7592 - val_loss: 0.8781 - val_accuracy: 0.5528\n","Epoch 8/30\n","16/16 [==============================] - 10s 647ms/step - loss: 0.6591 - accuracy: 0.7092 - val_loss: 1.4462 - val_accuracy: 0.4959\n","Epoch 9/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.5103 - accuracy: 0.7949 - val_loss: 2.0884 - val_accuracy: 0.4837\n","Epoch 10/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.5267 - accuracy: 0.7765 - val_loss: 1.2913 - val_accuracy: 0.5081\n","Epoch 11/30\n","16/16 [==============================] - 10s 655ms/step - loss: 0.5294 - accuracy: 0.7765 - val_loss: 1.7537 - val_accuracy: 0.5285\n","Epoch 12/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.3129 - accuracy: 0.8745 - val_loss: 1.3915 - val_accuracy: 0.5163\n","Epoch 13/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.4343 - accuracy: 0.8194 - val_loss: 3.1422 - val_accuracy: 0.4715\n","Epoch 14/30\n","16/16 [==============================] - 10s 652ms/step - loss: 0.3782 - accuracy: 0.8541 - val_loss: 2.6827 - val_accuracy: 0.4797\n","Epoch 15/30\n","16/16 [==============================] - 10s 652ms/step - loss: 0.2098 - accuracy: 0.9265 - val_loss: 1.6443 - val_accuracy: 0.5976\n","Epoch 16/30\n","16/16 [==============================] - 10s 650ms/step - loss: 0.1982 - accuracy: 0.9337 - val_loss: 1.6126 - val_accuracy: 0.5447\n","Epoch 17/30\n","16/16 [==============================] - 10s 647ms/step - loss: 0.2178 - accuracy: 0.9133 - val_loss: 1.5701 - val_accuracy: 0.6016\n","Epoch 18/30\n","16/16 [==============================] - 10s 649ms/step - loss: 0.2072 - accuracy: 0.9276 - val_loss: 1.3991 - val_accuracy: 0.5650\n","Epoch 19/30\n","16/16 [==============================] - 10s 653ms/step - loss: 0.1112 - accuracy: 0.9612 - val_loss: 1.5117 - val_accuracy: 0.6301\n","Epoch 20/30\n","16/16 [==============================] - 10s 648ms/step - loss: 0.0411 - accuracy: 0.9898 - val_loss: 1.6989 - val_accuracy: 0.6098\n","Epoch 21/30\n","16/16 [==============================] - 10s 649ms/step - loss: 0.0717 - accuracy: 0.9776 - val_loss: 1.3735 - val_accuracy: 0.6301\n","Epoch 22/30\n","16/16 [==============================] - 10s 650ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 1.8311 - val_accuracy: 0.5691\n","Epoch 23/30\n","16/16 [==============================] - 10s 652ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 2.0248 - val_accuracy: 0.6179\n","Epoch 24/30\n","16/16 [==============================] - 10s 650ms/step - loss: 0.0695 - accuracy: 0.9786 - val_loss: 1.9177 - val_accuracy: 0.6016\n","Epoch 25/30\n","16/16 [==============================] - 10s 650ms/step - loss: 0.1442 - accuracy: 0.9439 - val_loss: 2.1481 - val_accuracy: 0.5854\n","Epoch 26/30\n","16/16 [==============================] - 10s 651ms/step - loss: 0.1212 - accuracy: 0.9541 - val_loss: 3.6315 - val_accuracy: 0.4024\n","Epoch 27/30\n","16/16 [==============================] - 10s 654ms/step - loss: 0.0988 - accuracy: 0.9704 - val_loss: 2.5743 - val_accuracy: 0.5569\n","Epoch 28/30\n","16/16 [==============================] - 10s 652ms/step - loss: 0.0498 - accuracy: 0.9806 - val_loss: 1.9179 - val_accuracy: 0.5976\n","Epoch 29/30\n","16/16 [==============================] - 10s 651ms/step - loss: 0.0943 - accuracy: 0.9643 - val_loss: 2.6395 - val_accuracy: 0.5488\n","Epoch 30/30\n","16/16 [==============================] - 10s 651ms/step - loss: 0.1439 - accuracy: 0.9510 - val_loss: 2.1094 - val_accuracy: 0.5813\n","31/31 [==============================] - 3s 97ms/step - loss: 0.2382 - accuracy: 0.9224\n","8/8 [==============================] - 1s 122ms/step - loss: 2.1094 - accuracy: 0.5813\n","5/5 [==============================] - 1s 128ms/step - loss: 2.3313 - accuracy: 0.6233\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"psmsOlv-FIjx"},"source":["### Resnet 152"]},{"cell_type":"code","metadata":{"id":"KD32-8U2-E4s","executionInfo":{"status":"ok","timestamp":1602745357047,"user_tz":420,"elapsed":6094,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"f89e815c-c99e-4601-ebb3-309fffbcd3c1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Ref: https://keras.io/api/applications/resnet/\n","ResNet152 = tf.keras.applications.ResNet152(\n","    include_top=True,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=input_shape,\n","    pooling= max,\n","    classes= num_class,\n","    classifier_activation=\"softmax\",\n",")\n","\n","ResNet152.summary()"],"execution_count":241,"outputs":[{"output_type":"stream","text":["Model: \"resnet152\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_37 (InputLayer)           [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_37[0][0]                   \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_2_relu (Activation (None, 28, 28, 128)  0           conv3_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_add (Add)          (None, 28, 28, 512)  0           conv3_block4_out[0][0]           \n","                                                                 conv3_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_out (Activation)   (None, 28, 28, 512)  0           conv3_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_2_relu (Activation (None, 28, 28, 128)  0           conv3_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_add (Add)          (None, 28, 28, 512)  0           conv3_block5_out[0][0]           \n","                                                                 conv3_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_out (Activation)   (None, 28, 28, 512)  0           conv3_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_2_relu (Activation (None, 28, 28, 128)  0           conv3_block7_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block7_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block7_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_add (Add)          (None, 28, 28, 512)  0           conv3_block6_out[0][0]           \n","                                                                 conv3_block7_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_out (Activation)   (None, 28, 28, 512)  0           conv3_block7_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block7_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_2_relu (Activation (None, 28, 28, 128)  0           conv3_block8_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block8_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block8_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_add (Add)          (None, 28, 28, 512)  0           conv3_block7_out[0][0]           \n","                                                                 conv3_block8_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_out (Activation)   (None, 28, 28, 512)  0           conv3_block8_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block8_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block8_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n","                                                                 conv4_block7_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n","                                                                 conv4_block8_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n","                                                                 conv4_block9_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n","                                                                 conv4_block10_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n","                                                                 conv4_block11_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n","                                                                 conv4_block12_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n","                                                                 conv4_block13_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n","                                                                 conv4_block14_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n","                                                                 conv4_block15_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n","                                                                 conv4_block16_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n","                                                                 conv4_block17_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n","                                                                 conv4_block18_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n","                                                                 conv4_block19_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n","                                                                 conv4_block20_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n","                                                                 conv4_block21_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n","                                                                 conv4_block22_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n","                                                                 conv4_block23_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block23_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block24_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_add (Add)         (None, 14, 14, 1024) 0           conv4_block23_out[0][0]          \n","                                                                 conv4_block24_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_out (Activation)  (None, 14, 14, 1024) 0           conv4_block24_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block25_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block24_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block25_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block25_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block25_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block25_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block25_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block25_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block25_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block25_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block25_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block25_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block25_add (Add)         (None, 14, 14, 1024) 0           conv4_block24_out[0][0]          \n","                                                                 conv4_block25_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block25_out (Activation)  (None, 14, 14, 1024) 0           conv4_block25_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block26_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block25_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block26_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block26_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block26_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block26_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block26_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block26_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block26_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block26_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block26_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block26_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block26_add (Add)         (None, 14, 14, 1024) 0           conv4_block25_out[0][0]          \n","                                                                 conv4_block26_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block26_out (Activation)  (None, 14, 14, 1024) 0           conv4_block26_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block27_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block26_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block27_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block27_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block27_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block27_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block27_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block27_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block27_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block27_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block27_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block27_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block27_add (Add)         (None, 14, 14, 1024) 0           conv4_block26_out[0][0]          \n","                                                                 conv4_block27_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block27_out (Activation)  (None, 14, 14, 1024) 0           conv4_block27_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block28_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block27_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block28_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block28_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block28_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block28_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block28_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block28_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block28_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block28_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block28_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block28_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block28_add (Add)         (None, 14, 14, 1024) 0           conv4_block27_out[0][0]          \n","                                                                 conv4_block28_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block28_out (Activation)  (None, 14, 14, 1024) 0           conv4_block28_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block29_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block28_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block29_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block29_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block29_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block29_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block29_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block29_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block29_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block29_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block29_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block29_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block29_add (Add)         (None, 14, 14, 1024) 0           conv4_block28_out[0][0]          \n","                                                                 conv4_block29_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block29_out (Activation)  (None, 14, 14, 1024) 0           conv4_block29_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block30_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block29_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block30_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block30_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block30_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block30_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block30_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block30_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block30_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block30_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block30_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block30_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block30_add (Add)         (None, 14, 14, 1024) 0           conv4_block29_out[0][0]          \n","                                                                 conv4_block30_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block30_out (Activation)  (None, 14, 14, 1024) 0           conv4_block30_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block31_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block30_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block31_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block31_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block31_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block31_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block31_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block31_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block31_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block31_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block31_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block31_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block31_add (Add)         (None, 14, 14, 1024) 0           conv4_block30_out[0][0]          \n","                                                                 conv4_block31_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block31_out (Activation)  (None, 14, 14, 1024) 0           conv4_block31_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block32_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block31_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block32_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block32_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block32_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block32_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block32_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block32_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block32_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block32_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block32_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block32_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block32_add (Add)         (None, 14, 14, 1024) 0           conv4_block31_out[0][0]          \n","                                                                 conv4_block32_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block32_out (Activation)  (None, 14, 14, 1024) 0           conv4_block32_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block33_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block32_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block33_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block33_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block33_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block33_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block33_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block33_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block33_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block33_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block33_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block33_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block33_add (Add)         (None, 14, 14, 1024) 0           conv4_block32_out[0][0]          \n","                                                                 conv4_block33_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block33_out (Activation)  (None, 14, 14, 1024) 0           conv4_block33_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block34_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block33_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block34_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block34_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block34_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block34_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block34_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block34_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block34_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block34_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block34_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block34_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block34_add (Add)         (None, 14, 14, 1024) 0           conv4_block33_out[0][0]          \n","                                                                 conv4_block34_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block34_out (Activation)  (None, 14, 14, 1024) 0           conv4_block34_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block35_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block34_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block35_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block35_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block35_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block35_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block35_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block35_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block35_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block35_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block35_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block35_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block35_add (Add)         (None, 14, 14, 1024) 0           conv4_block34_out[0][0]          \n","                                                                 conv4_block35_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block35_out (Activation)  (None, 14, 14, 1024) 0           conv4_block35_add[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block36_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block35_out[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block36_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block36_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block36_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block36_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block36_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block36_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_2_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block36_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block36_2_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block36_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block36_3_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block36_add (Add)         (None, 14, 14, 1024) 0           conv4_block35_out[0][0]          \n","                                                                 conv4_block36_3_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block36_out (Activation)  (None, 14, 14, 1024) 0           conv4_block36_add[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block36_out[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block36_out[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 3)            6147        avg_pool[0][0]                   \n","==================================================================================================\n","Total params: 58,377,091\n","Trainable params: 58,225,667\n","Non-trainable params: 151,424\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uO5y8vy5t52s","executionInfo":{"status":"error","timestamp":1602745233418,"user_tz":420,"elapsed":20401,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"fbe0f173-db78-49bd-b99c-209e295eb63e","colab":{"base_uri":"https://localhost:8080/","height":494}},"source":["# out of meomery \n","history = compile_and_fit(ResNet152)\n","\n","train_performance['ResNet152'] = ResNet152.evaluate(train_x, train_y, verbose= 1)\n","val_performance['ResNet152'] = ResNet152.evaluate(val_x, val_y, verbose= 1)\n","performance['ResNet152'] = ResNet152.evaluate(test_X, test_y, verbose= 1)"],"execution_count":240,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-240-83f412dd48c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet152\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResNet152'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-209-14c910bc6e56>\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, patience, MAX_EPOCHS, early_stop, val_split, decay_step, batch_size, initial_lr, lr_decay_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,256,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet101/conv2_block3_3_bn/FusedBatchNormV3 (defined at <ipython-input-209-14c910bc6e56>:14) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_415347]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"markdown","metadata":{"id":"qVc7J3G-dseB"},"source":["## Performance"]},{"cell_type":"code","metadata":{"id":"IyaIO-565Viy","executionInfo":{"status":"ok","timestamp":1602745715181,"user_tz":420,"elapsed":498,"user":{"displayName":"Chun-Liang Wu","photoUrl":"","userId":"12330002015168332955"}},"outputId":"321f803e-5818-4a8d-ab31-7c6f14e52024","colab":{"base_uri":"https://localhost:8080/","height":543}},"source":["x = np.arange(len(performance))\n","width = 0.2\n","\n","metric_name = 'accuracy'\n","metric_index = AlexNet.metrics_names.index('accuracy')\n","train_acc = [v[metric_index] for v in train_performance.values()]\n","val_acc = [v[metric_index] for v in val_performance.values()]\n","test_acc = [v[metric_index] for v in performance.values()]\n","\n","plt.figure(figsize=(12, 8))\n","plt.bar(x - 0.23, train_acc, width, label='Training')\n","plt.bar(x, val_acc, width, label='Validation')\n","plt.bar(x + 0.23, test_acc, width, label='Test')\n","plt.xticks(ticks=x, labels=performance.keys(),\n","           rotation=45)\n","plt.ylabel('Accuracy')\n","_ = plt.legend()"],"execution_count":246,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}